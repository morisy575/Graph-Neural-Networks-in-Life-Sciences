{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e39b7f6",
   "metadata": {},
   "source": [
    "## DGL-LifeSci with PyTorchバックエンドを使用した結合親和性予測用Amazon SageMakerモデルのトレーニング\n",
    "**Amazon SageMaker Python SDK**を使用すると、DGL-LifeSciモデルを簡単にトレーニングすることができます。この例では、[PDBBind](http://www.pdbbind.org.cn/)データセットを使ってAtomic Convolutional Networks (ACNN) [1] またはPotentialNet [2] モデルを学習させます。これらの詳細については、[DGL-Lifesciのサンプルページ](https://github.com/yoheigon/dgl-lifesci/tree/master/examples/binding_affinity_prediction)を参照してください。\n",
    "\n",
    "[1] Gomes et al. (2017) Atomic Convolutional Networks for Predicting Protein-Ligand Binding Affinity. *arXiv preprint arXiv:1703.10603*.\n",
    "\n",
    "[2] Feinberg et al. (2018) PotentialNet for molecular property prediction. *ACS central science* 4.11: 1520-1530."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e653105",
   "metadata": {},
   "source": [
    "### セットアップ\n",
    "後々必要になるいくつかの変数をここで定義しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8806ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "# You can use the Amazon SageMaker Python SDK to get the role from the notebook environment.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce14738f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-ap-northeast-1-233488627969'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d7e72",
   "metadata": {},
   "source": [
    "### 学習スクリプト\n",
    "`main.py`は、Amazon SageMaker モデルのトレーニングに必要なすべてのコードを提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e99067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\n",
      "#\n",
      "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
      "# SPDX-License-Identifier: Apache-2.0\n",
      "\n",
      "import multiprocessing\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "import json\n",
      "import glob\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from torch.utils.data import DataLoader, Dataset\n",
      "\n",
      "import dgl\n",
      "from dgllife.utils.eval import Meter\n",
      "from dgl.data.utils import Subset, extract_archive\n",
      "from dgl.data.utils import load_graphs\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "from utils import load_dataset, load_model, rand_hyperparams, set_random_seed\n",
      "\n",
      "import pandas as pd\n",
      "import boto3\n",
      "\n",
      "\n",
      "def update_msg_from_scores(msg, scores):\n",
      "    for metric, score in scores.items():\n",
      "        msg += \", {} {:.4f}\".format(metric, score)\n",
      "    return msg\n",
      "\n",
      "\n",
      "def run_a_train_epoch(args, epoch, model, data_loader, loss_criterion, optimizer):\n",
      "    model.train()\n",
      "    train_meter = Meter(args[\"train_mean\"], args[\"train_std\"])\n",
      "    epoch_loss = 0\n",
      "    for batch_id, batch_data in enumerate(data_loader):\n",
      "        bg, labels = batch_data\n",
      "        labels = labels.to(args[\"device\"])\n",
      "        if args[\"model\"] == \"PotentialNet\":\n",
      "            bigraph_canonical, knn_graph = bg  # unpack stage1_graph, stage2_graph\n",
      "            bigraph_canonical = bigraph_canonical.to(args[\"device\"])\n",
      "            knn_graph = knn_graph.to(args[\"device\"])\n",
      "            prediction = model(bigraph_canonical, knn_graph)\n",
      "        elif args[\"model\"] == \"ACNN\":\n",
      "            bg = bg.to(args[\"device\"])\n",
      "            prediction = model(bg)\n",
      "        loss = loss_criterion(prediction, (labels - args[\"train_mean\"]) / args[\"train_std\"])\n",
      "        epoch_loss += loss.data.item() * len(labels)\n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_meter.update(prediction, labels)\n",
      "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
      "    # if (args['num_epochs'] - epoch) <= 6: # print only the last 5 epochs\n",
      "    total_scores = {\n",
      "        metric: train_meter.compute_metric(metric, \"mean\") for metric in args[\"metrics\"]\n",
      "    }\n",
      "    msg = \"epoch {:d}/{:d}, training | loss {:.4f}\".format(epoch + 1, args[\"num_epochs\"], avg_loss)\n",
      "    msg = update_msg_from_scores(msg, total_scores)\n",
      "    print(msg)\n",
      "    return total_scores\n",
      "\n",
      "\n",
      "def run_an_eval_epoch(args, model, data_loader):\n",
      "    model.eval()\n",
      "    eval_meter = Meter(args[\"train_mean\"], args[\"train_std\"])\n",
      "    with torch.no_grad():\n",
      "        for batch_id, batch_data in enumerate(data_loader):\n",
      "            bg, labels = batch_data\n",
      "            labels = labels.to(args[\"device\"])\n",
      "            if args[\"model\"] == \"PotentialNet\":\n",
      "                bigraph_canonical, knn_graph = bg  # unpack\n",
      "                bigraph_canonical = bigraph_canonical.to(args[\"device\"])\n",
      "                knn_graph = knn_graph.to(args[\"device\"])\n",
      "                prediction = model(bigraph_canonical, knn_graph)\n",
      "            elif args[\"model\"] == \"ACNN\":\n",
      "                bg = bg.to(args[\"device\"])\n",
      "                prediction = model(bg)\n",
      "            eval_meter.update(prediction, labels)\n",
      "    total_scores = {metric: eval_meter.compute_metric(metric, \"mean\") for metric in args[\"metrics\"]}\n",
      "    return total_scores\n",
      "\n",
      "class MyDataset(Dataset):\n",
      "    def __init__(self, lst_graph1_paths):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.len = len(lst_graph1_paths)\n",
      "        self.lst = lst_graph1_paths\n",
      "        \n",
      "    def __len__(self):\n",
      "        return self.len\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        graphs1, label_dict = load_graphs(self.lst[index])\n",
      "        graphs2, label_dict = load_graphs(self.lst[index].replace('_g1.bin', '_g2.bin'))\n",
      "        label = label_dict['glabel']\n",
      "        \n",
      "        graphs1_batch = [dgl.batch([graphs1[i],graphs1[i+1]]) for i in range(0, int(len(graphs1)), 2)]\n",
      "        bg = [tuple([graphs1_batch[i],graphs2[i]]) for i in range(0, int(len(graphs2)), 1)]\n",
      "        \n",
      "        return bg[0], label\n",
      "    \n",
      "def collate(data):\n",
      "    graphs, labels = map(list, zip(*data))\n",
      "    if (type(graphs[0]) == tuple):\n",
      "        bg1 = dgl.batch([g[0] for g in graphs])\n",
      "        bg2 = dgl.batch([g[1] for g in graphs])\n",
      "        bg = (bg1, bg2) # return a tuple for PotentialNet\n",
      "    else:\n",
      "        bg = dgl.batch(graphs)\n",
      "        for nty in bg.ntypes:\n",
      "            bg.set_n_initializer(dgl.init.zero_initializer, ntype=nty)\n",
      "        for ety in bg.canonical_etypes:\n",
      "            bg.set_e_initializer(dgl.init.zero_initializer, etype=ety)\n",
      "\n",
      "    labels = torch.stack(labels, dim=0)\n",
      "    return bg, labels\n",
      "\n",
      "\n",
      "def main(args):\n",
      "\n",
      "    torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
      "    args[\"device\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    set_random_seed(args[\"random_seed\"])\n",
      "    \n",
      "    lst_csv = []\n",
      "    lst_csv += glob.glob(args[\"data_dir\"] +\"/\"+ \"**.csv\")\n",
      "    assert len(lst_csv) <= 1 # Make sure there aren't more than 1 csv files. \n",
      "    print(lst_csv)\n",
      "    \n",
      "    if len(lst_csv) == 1: # There is a csv file for split instruction \n",
      "        _lst_g1_train = pd.read_csv(lst_csv[0])[pd.read_csv(lst_csv[0])['split'] == 'train']['g1_bin'].to_list()\n",
      "        _lst_g1_val = pd.read_csv(lst_csv[0])[pd.read_csv(lst_csv[0])['split'] == 'val']['g1_bin'].to_list()\n",
      "        _lst_g1_test = pd.read_csv(lst_csv[0])[pd.read_csv(lst_csv[0])['split'] == 'test']['g1_bin'].to_list()\n",
      "        \n",
      "        lst_g1_train = [args[\"data_dir\"] +\"/\"+ pdb for pdb in _lst_g1_train]\n",
      "        lst_g1_val = [args[\"data_dir\"] +\"/\"+ pdb for pdb in _lst_g1_val]\n",
      "        lst_g1_test = [args[\"data_dir\"] +\"/\"+ pdb for pdb in _lst_g1_test]\n",
      "        \n",
      "        train_set = MyDataset(lst_g1_train)\n",
      "        val_set = MyDataset(lst_g1_val)\n",
      "        test_set = MyDataset(lst_g1_test)\n",
      "        \n",
      "    else: # If there is no csv file, use random split. \n",
      "        lst_g1 = glob.glob(args[\"data_dir\"] +\"/\"+ \"**_g1.bin\")\n",
      "        print(lst_g1)\n",
      "        \n",
      "        lst_g1_train, lst_g1_val = train_test_split(lst_g1, test_size=0.33, random_state=42)\n",
      "        \n",
      "        train_set = MyDataset(lst_g1_train)\n",
      "        val_set = MyDataset(lst_g1_val)\n",
      "        test_set = MyDataset(lst_g1_val)\n",
      "    \n",
      "    train_labels = torch.stack([g[1] for g in train_set])\n",
      "    train_set.labels_mean = train_labels.mean(dim=0)\n",
      "    train_set.labels_std = train_labels.std(dim=0)\n",
      "    \n",
      "    \n",
      "    args[\"train_mean\"] = train_set.labels_mean.to(args[\"device\"])\n",
      "    args[\"train_std\"] = train_set.labels_std.to(args[\"device\"])\n",
      "    \n",
      "\n",
      "    print(\"Data Loader\")\n",
      "    train_loader = DataLoader(\n",
      "        dataset=train_set,\n",
      "        batch_size=args[\"batch_size\"],\n",
      "        shuffle=args[\"shuffle\"],\n",
      "        collate_fn=collate,\n",
      "        pin_memory=True,\n",
      "        num_workers=args[\"num_workers\"],\n",
      "    )\n",
      "    test_loader = DataLoader(\n",
      "        dataset=test_set,\n",
      "        batch_size=args[\"batch_size\"],\n",
      "        collate_fn=collate,\n",
      "        pin_memory=True,\n",
      "        num_workers=args[\"num_workers\"],\n",
      "    )\n",
      "    val_loader = DataLoader(\n",
      "        dataset=val_set,\n",
      "        batch_size=args[\"batch_size\"],\n",
      "        collate_fn=collate,\n",
      "        pin_memory=True,\n",
      "        num_workers=args[\"num_workers\"],\n",
      "    )\n",
      "    \n",
      "    # Get distance_bins length\n",
      "    for i0, g in enumerate(train_set):\n",
      "        g2_edge_dim = g[0][1].edata['e'].shape[1]\n",
      "        break\n",
      "\n",
      "    print(f\"g2_edge_dim : {g2_edge_dim - 5}\")\n",
      "    fake_distance_bins = [i1 for i1 in range(g2_edge_dim - 5)]\n",
      "    args['distance_bins'] = fake_distance_bins\n",
      "    \n",
      "    model = load_model(args)\n",
      "    if args['fine_tune']:\n",
      "        print('--Fine Tune--')\n",
      "        s3_bucket = args['pretrained_model'].split('/')[2]\n",
      "        object_name = '/'.join(args['pretrained_model'].split('/')[3:])\n",
      "        file_name = args['pretrained_model'].split('/')[-1]\n",
      "        s3 = boto3.client('s3')\n",
      "        with open(file_name, 'wb') as f:\n",
      "            s3.download_fileobj(s3_bucket, object_name, f)\n",
      "        extract_archive('model.tar.gz', '')\n",
      "        model.load_state_dict(torch.load('best_test_model.pth'))\n",
      "        \n",
      "        ## Freeze Param\n",
      "        print('--Freeze Params--')\n",
      "        for i1, child in enumerate(model.children()):\n",
      "            print(child)\n",
      "            for param in child.parameters():\n",
      "                param.requires_grad = False\n",
      "            if i1 == 1:\n",
      "                break\n",
      "        \n",
      "    \n",
      "    if args[\"num_gpus\"] > 1:\n",
      "        print(\"Gpu count: {}\".format(args[\"num_gpus\"]))\n",
      "        model = nn.DataParallel(model)\n",
      "        \n",
      "    ### This is something we can work with mask ###\n",
      "    \n",
      "    loss_fn = nn.MSELoss()\n",
      "    \n",
      "    \n",
      "    optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"], weight_decay=args[\"wd\"])\n",
      "    model.to(args[\"device\"])\n",
      "    n_epochs = args[\"num_epochs\"]\n",
      "    \n",
      "    train_r2, val_r2, test_r2 = np.zeros(n_epochs), np.zeros(n_epochs), np.zeros(n_epochs)\n",
      "    for epoch in range(n_epochs):\n",
      "        train_scores = run_a_train_epoch(args, epoch, model, train_loader, loss_fn, optimizer)\n",
      "        train_r2[epoch] = train_scores[\"r2\"]\n",
      "        if len(val_set) > 0:\n",
      "            val_scores = run_an_eval_epoch(args, model, val_loader)\n",
      "            val_msg = update_msg_from_scores(\"validation results\", val_scores)\n",
      "            print(val_msg)\n",
      "            print(f\"------\")\n",
      "            print(f\"val mae:{val_msg.split('mae')[-1]}\")\n",
      "            print(f\"val r2:{val_msg.split('r2')[-1].split(',')[0]}\")\n",
      "            print(f\"------\")\n",
      "            val_r2[epoch] = val_scores[\"r2\"]\n",
      "        if len(test_set) > 0:\n",
      "            test_scores = run_an_eval_epoch(args, model, test_loader)\n",
      "            test_msg = update_msg_from_scores(\"test results\", test_scores)\n",
      "            print(test_msg)\n",
      "            print(f\"------\")\n",
      "            print(f\"test mae:{test_msg.split('mae')[-1]}\")\n",
      "            print(f\"test r2:{test_msg.split('r2')[-1].split(',')[0]}\")\n",
      "            print(f\"------\")\n",
      "            test_r2[epoch] = test_scores[\"r2\"]\n",
      "            print(\"\")\n",
      "                   \n",
      "        best_epoch = np.argmax(val_r2)\n",
      "        if epoch == best_epoch and best_epoch != 0 and not np.isnan(val_r2[best_epoch]) :\n",
      "            print(\"Best val epoch: \", best_epoch + 1)\n",
      "        \n",
      "            print(\"Saving the model\")\n",
      "            path = os.path.join(args[\"model_dir\"], \"best_val_model.pth\")\n",
      "            # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
      "            # This model artifact is on GPU      \n",
      "            torch.save(model.state_dict(), path)\n",
      "\n",
      "        best_epoch = np.argmax(test_r2)\n",
      "        if epoch == best_epoch and best_epoch != 0 and not np.isnan(test_r2[best_epoch]) :\n",
      "            print(\"Best test epoch: \", best_epoch + 1)\n",
      "        \n",
      "            print(\"Saving the model\")\n",
      "            path = os.path.join(args[\"model_dir\"], \"best_test_model.pth\")\n",
      "            # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
      "            # This model artifact is on GPU \n",
      "            torch.save(model.state_dict(), path)\n",
      "                  \n",
      "        print(\"\")\n",
      "                  \n",
      "    # save model r2 at each epoch\n",
      "    if args[\"save_r2\"]:\n",
      "        os.makedirs(args[\"save_r2\"], exist_ok=True)\n",
      "        save_path = args[\"save_r2\"] + \"/{}_{}_{}_{}.npz\".format(\n",
      "            args[\"model\"], args[\"version\"], args[\"subset\"], args[\"split\"]\n",
      "        )\n",
      "        np.savez(save_path, train_r2=train_r2, val_r2=val_r2, test_r2=test_r2)\n",
      "\n",
      "        # save results on the epoch with best validation r2\n",
      "        best_epoch = np.argmax(val_r2)\n",
      "        print(\"Best test epoch: \", best_epoch + 1)\n",
      "                  \n",
      "    print(\"Saving the model\")\n",
      "    path = os.path.join(args[\"model_dir\"], \"model.pth\")\n",
      "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
      "    torch.save(model.cpu().state_dict(), path)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    import argparse\n",
      "\n",
      "    from configure import get_exp_configure\n",
      "\n",
      "    parser = argparse.ArgumentParser(description=\"Protein-Ligand Binding Affinity Prediction\")\n",
      "    parser.add_argument(\n",
      "        \"-m\", \"--model\", type=str, choices=[\"ACNN\", \"PotentialNet\"], help=\"Model to use\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"-d\",\n",
      "        \"--dataset_option\",\n",
      "        type=str,\n",
      "        choices=[\n",
      "            \"PDBBind_core_pocket_random\",\n",
      "            \"PDBBind_core_pocket_scaffold\",\n",
      "            \"PDBBind_core_pocket_stratified\",\n",
      "            \"PDBBind_core_pocket_temporal\",\n",
      "            \"PDBBind_refined_pocket_random\",\n",
      "            \"PDBBind_refined_pocket_scaffold\",\n",
      "            \"PDBBind_refined_pocket_stratified\",\n",
      "            \"PDBBind_refined_pocket_temporal\",\n",
      "            \"PDBBind_refined_pocket_structure\",\n",
      "            \"PDBBind_refined_pocket_sequence\",\n",
      "        ],\n",
      "        help=\"Data subset and split to use\",\n",
      "    )\n",
      "    #parser.add_argument(\n",
      "    #    \"--pdb_path\", type=str, default=None, help=\"local path of custom PDBBind dataset\"\n",
      "    #)\n",
      "    parser.add_argument(\"-v\", \"--version\", type=str, choices=[\"v2007\", \"v2015\"], default=\"v2015\")\n",
      "    parser.add_argument(\n",
      "        \"--num_workers\",\n",
      "        type=int,\n",
      "        default=0,\n",
      "        help=\"number of processes for loading PDBBind molecules and Dataloader\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--save_r2\", type=str, default=\"\", help=\"path to save r2 at each epoch, default not save\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--test_on_core\",\n",
      "        type=bool,\n",
      "        default=True,\n",
      "        help=\"whether to use the whole core set as test set when training on refined set, default True\",\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
      "    parser.add_argument(\"--current-host\", type=str, default=os.environ[\"SM_CURRENT_HOST\"])\n",
      "    parser.add_argument(\"--hosts\", type=list, default=json.loads(os.environ[\"SM_HOSTS\"]))\n",
      "    parser.add_argument(\"--num-gpus\", type=int, default=os.environ[\"SM_NUM_GPUS\"])\n",
      "    #parser.add_argument(\"--data-dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
      "    \n",
      "\n",
      "    parser.add_argument(\"--lr\", type=float, default=argparse.SUPPRESS)\n",
      "    parser.add_argument(\"--wd\", type=float, default=argparse.SUPPRESS)\n",
      "    parser.add_argument(\"--num_epochs\", type=int, default=argparse.SUPPRESS)\n",
      "    parser.add_argument(\"--distance_bins\", type=lambda s: json.loads(s.replace(\"'\", '\"')),default=argparse.SUPPRESS)\n",
      "    parser.add_argument(\"--fine_tune\", type=bool, default=False)\n",
      "    parser.add_argument(\"--pretrained_model\", type=str, default=\"\")\n",
      "\n",
      "    args = parser.parse_args().__dict__\n",
      "\n",
      "    args[\"model\"] = \"PotentialNet\"\n",
      "    args[\"dataset_option\"] = \"PDBBind_refined_pocket_scaffold\"\n",
      "    args[\"exp\"] = \"_\".join([args[\"model\"], args[\"dataset_option\"]])\n",
      "    #args[\"exp\"] = \"PotentialNet_PDBBind_refined_pocket_scaffold\"\n",
      "    \n",
      "    if os.environ.get(\"SM_CHANNEL_TRAIN\"):\n",
      "        args[\"data_dir\"] = os.environ[\"SM_CHANNEL_TRAIN\"]\n",
      "\n",
      "    default_exp = get_exp_configure(args[\"exp\"])\n",
      "    for i in default_exp.keys():\n",
      "        args.setdefault(i, default_exp[i])\n",
      "\n",
      "    if args[\"num_workers\"] == 0:\n",
      "        args[\"num_workers\"] = multiprocessing.cpu_count()\n",
      "\n",
      "    #### We don't need to use this #### \n",
      "    #if args[\"split\"] == \"sequence\" or args[\"split\"] == \"structure\":\n",
      "    #    args[\"version\"] = \"v2007\"\n",
      "    #    args[\"test_on_core\"] = False\n",
      "    #    args[\"remove_coreset_from_refinedset\"] = False\n",
      "    #\n",
      "    #if args[\"subset\"] == \"core\":\n",
      "    #    args[\"remove_coreset_from_refinedset\"] = False\n",
      "    #    args[\"test_on_core\"] = False\n",
      "    #### We don't need to use this #### \n",
      "    \n",
      "    #if args[\"pdb_path\"]:\n",
      "    #    args[\"pdb_path\"] = os.environ[\"SM_CHANNEL_TRAIN\"] + args[\"pdb_path\"]\n",
      "\n",
      "    rand_hyper_search = False\n",
      "    if rand_hyper_search:  # randomly initialize hyperparameters\n",
      "        customized_hps = rand_hyperparams()\n",
      "        args.update(customized_hps)\n",
      "    for k, v in args.items():\n",
      "        print(f\"{k}: {v}\")\n",
      "\n",
      "    print(\"\")\n",
      "    main(args)\n"
     ]
    }
   ],
   "source": [
    "!cat ./code/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069a4c9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-16 03:16:07     118822 1a30_g1.bin\n",
      "2022-12-16 03:16:07     353707 1a30_g2.bin\n",
      "2022-12-16 03:16:07      94262 1bcu_g1.bin\n",
      "2022-12-16 03:16:07     278347 1bcu_g2.bin\n",
      "2022-12-16 03:16:07     118622 1bzc_g1.bin\n",
      "2022-12-16 03:16:07     353467 1bzc_g2.bin\n",
      "2022-12-16 03:16:07     142814 1e66_g1.bin\n",
      "2022-12-16 03:16:07     428827 1e66_g2.bin\n",
      "2022-12-16 03:16:07     168070 1eby_g1.bin\n",
      "2022-12-16 03:16:07     506227 1eby_g2.bin\n",
      "2022-12-16 03:16:07     161326 1g2k_g1.bin\n",
      "2022-12-16 03:16:07     485827 1g2k_g2.bin\n",
      "2022-12-16 03:16:07     127374 1gpk_g1.bin\n",
      "2022-12-16 03:16:07     381307 1gpk_g2.bin\n",
      "2022-12-16 03:16:07     135254 1gpn_g1.bin\n",
      "2022-12-16 03:16:07     406027 1gpn_g2.bin\n",
      "2022-12-16 03:16:07     184182 1h22_g1.bin\n",
      "2022-12-16 03:16:07     556747 1h22_g2.bin\n",
      "2022-12-16 03:16:07     191390 1h23_g1.bin\n",
      "2022-12-16 03:16:07     578587 1h23_g2.bin\n",
      "2022-12-16 03:16:08     115462 1k1i_g1.bin\n",
      "2022-12-16 03:16:07     342907 1k1i_g2.bin\n",
      "2022-12-16 03:16:07     147758 1lpg_g1.bin\n",
      "2022-12-16 03:16:08     443707 1lpg_g2.bin\n",
      "2022-12-16 03:16:07     146182 1mq6_g1.bin\n",
      "2022-12-16 03:16:07     439147 1mq6_g2.bin\n",
      "2022-12-16 03:16:07     128726 1nc1_g1.bin\n",
      "2022-12-16 03:16:07     384907 1nc1_g2.bin\n",
      "2022-12-16 03:16:08     119390 1nc3_g1.bin\n",
      "2022-12-16 03:16:07     355867 1nc3_g2.bin\n",
      "2022-12-16 03:16:07     142758 1nvq_g1.bin\n",
      "2022-12-16 03:16:07     428587 1nvq_g2.bin\n",
      "2022-12-16 03:16:07     102862 1o0h_g1.bin\n",
      "2022-12-16 03:16:07     302587 1o0h_g2.bin\n",
      "2022-12-16 03:16:07     117174 1o3f_g1.bin\n",
      "2022-12-16 03:16:07     349387 1o3f_g2.bin\n",
      "2022-12-16 03:16:07     117406 1owh_g1.bin\n",
      "2022-12-16 03:16:08     350107 1owh_g2.bin\n",
      "2022-12-16 03:16:08     146726 1oyt_g1.bin\n",
      "2022-12-16 03:16:08     440107 1oyt_g2.bin\n",
      "2022-12-16 03:16:08     121542 1p1n_g1.bin\n",
      "2022-12-16 03:16:08     362347 1p1n_g2.bin\n",
      "2022-12-16 03:16:08     111622 1p1q_g1.bin\n",
      "2022-12-16 03:16:08     331627 1p1q_g2.bin\n",
      "2022-12-16 03:16:08     110470 1ps3_g1.bin\n",
      "2022-12-16 03:16:08     327547 1ps3_g2.bin\n",
      "2022-12-16 03:16:08     123702 1pxn_g1.bin\n",
      "2022-12-16 03:16:08     370147 1pxn_g2.bin\n",
      "2022-12-16 03:16:08     130982 1q8t_g1.bin\n",
      "2022-12-16 03:16:08     391987 1q8t_g2.bin\n",
      "2022-12-16 03:16:08     139518 1q8u_g1.bin\n",
      "2022-12-16 03:16:08     418267 1q8u_g2.bin\n",
      "2022-12-16 03:16:08     125758 1qf1_g1.bin\n",
      "2022-12-16 03:16:08     376027 1qf1_g2.bin\n",
      "2022-12-16 03:16:08     128902 1qkt_g1.bin\n",
      "2022-12-16 03:16:08     385387 1qkt_g2.bin\n",
      "2022-12-16 03:16:08      94454 1r5y_g1.bin\n",
      "2022-12-16 03:16:08     278347 1r5y_g2.bin\n",
      "2022-12-16 03:16:08     100726 1s38_g1.bin\n",
      "2022-12-16 03:16:08     297547 1s38_g2.bin\n",
      "2022-12-16 03:16:08     127486 1sqa_g1.bin\n",
      "2022-12-16 03:16:08     381667 1sqa_g2.bin\n",
      "2022-12-16 03:16:08     114334 1syi_g1.bin\n",
      "2022-12-16 03:16:08     340507 1syi_g2.bin\n",
      "2022-12-16 03:16:08     135246 1u1b_g1.bin\n",
      "2022-12-16 03:16:08     406267 1u1b_g2.bin\n",
      "2022-12-16 03:16:08      88414 1uto_g1.bin\n",
      "2022-12-16 03:16:08     259867 1uto_g2.bin\n",
      "2022-12-16 03:16:08     117870 1vso_g1.bin\n",
      "2022-12-16 03:16:08     349627 1vso_g2.bin\n",
      "2022-12-16 03:16:08      87014 1w4o_g1.bin\n",
      "2022-12-16 03:16:08     255787 1w4o_g2.bin\n",
      "2022-12-16 03:16:08     125822 1y6r_g1.bin\n",
      "2022-12-16 03:16:08     376027 1y6r_g2.bin\n",
      "2022-12-16 03:16:08     137230 1yc1_g1.bin\n",
      "2022-12-16 03:16:08     410107 1yc1_g2.bin\n",
      "2022-12-16 03:16:08     137358 1ydr_g1.bin\n",
      "2022-12-16 03:16:08     412027 1ydr_g2.bin\n",
      "2022-12-16 03:16:08     154950 1ydt_g1.bin\n",
      "2022-12-16 03:16:08     466027 1ydt_g2.bin\n",
      "2022-12-16 03:16:08     144614 1z6e_g1.bin\n",
      "2022-12-16 03:16:08     434347 1z6e_g2.bin\n",
      "2022-12-16 03:16:08     160790 1z95_g1.bin\n",
      "2022-12-16 03:16:08     484747 1z95_g2.bin\n",
      "2022-12-16 03:16:08     100574 1z9g_g1.bin\n",
      "2022-12-16 03:16:08     298027 1z9g_g2.bin\n",
      "2022-12-16 03:16:08     118942 2al5_g1.bin\n",
      "2022-12-16 03:16:08     353947 2al5_g2.bin\n",
      "2022-12-16 03:16:08     115174 2br1_g1.bin\n",
      "2022-12-16 03:16:08     342187 2br1_g2.bin\n",
      "2022-12-16 03:16:08     107670 2brb_g1.bin\n",
      "2022-12-16 03:16:08     319627 2brb_g2.bin\n",
      "2022-12-16 03:16:08     111438 2c3i_g1.bin\n",
      "2022-12-16 03:16:08     331387 2c3i_g2.bin\n",
      "2022-12-16 03:16:08     105526 2cbv_g1.bin\n",
      "2022-12-16 03:16:08     312547 2cbv_g2.bin\n",
      "2022-12-16 03:16:08     140094 2cet_g1.bin\n",
      "2022-12-16 03:16:08     419827 2cet_g2.bin\n",
      "2022-12-16 03:16:08     146486 2fvd_g1.bin\n",
      "2022-12-16 03:16:08     439627 2fvd_g2.bin\n",
      "2022-12-16 03:16:08     113798 2fxs_g1.bin\n",
      "2022-12-16 03:16:08     337387 2fxs_g2.bin\n",
      "2022-12-16 03:16:08     101158 2hb1_g1.bin\n",
      "2022-12-16 03:16:08     299947 2hb1_g2.bin\n",
      "2022-12-16 03:16:08     108758 2iwx_g1.bin\n",
      "2022-12-16 03:16:08     321187 2iwx_g2.bin\n",
      "2022-12-16 03:16:08     114942 2j78_g1.bin\n",
      "2022-12-16 03:16:08     341467 2j78_g2.bin\n",
      "2022-12-16 03:16:08     103726 2j7h_g1.bin\n",
      "2022-12-16 03:16:08     307027 2j7h_g2.bin\n",
      "2022-12-16 03:16:08     165918 2p15_g1.bin\n",
      "2022-12-16 03:16:08     499867 2p15_g2.bin\n",
      "2022-12-16 03:16:08     169590 2p4y_g1.bin\n",
      "2022-12-16 03:16:08     512587 2p4y_g2.bin\n",
      "2022-12-16 03:16:08     133526 2pog_g1.bin\n",
      "2022-12-16 03:16:08     400267 2pog_g2.bin\n",
      "2022-12-16 03:16:08     145246 2qbp_g1.bin\n",
      "2022-12-16 03:16:08     436507 2qbp_g2.bin\n",
      "2022-12-16 03:16:08     135478 2qbq_g1.bin\n",
      "2022-12-16 03:16:08     404947 2qbq_g2.bin\n",
      "2022-12-16 03:16:08     126006 2qbr_g1.bin\n",
      "2022-12-16 03:16:08     376147 2qbr_g2.bin\n",
      "2022-12-16 03:16:08     137518 2qe4_g1.bin\n",
      "2022-12-16 03:16:08     412987 2qe4_g2.bin\n",
      "2022-12-16 03:16:08     146574 2qnq_g1.bin\n",
      "2022-12-16 03:16:08     440827 2qnq_g2.bin\n",
      "2022-12-16 03:16:08     115310 2r9w_g1.bin\n",
      "2022-12-16 03:16:08     341947 2r9w_g2.bin\n",
      "2022-12-16 03:16:08     104734 2v00_g1.bin\n",
      "2022-12-16 03:16:08     309787 2v00_g2.bin\n",
      "2022-12-16 03:16:08     133070 2v7a_g1.bin\n",
      "2022-12-16 03:16:08     398587 2v7a_g2.bin\n",
      "2022-12-16 03:16:08     199230 2vkm_g1.bin\n",
      "2022-12-16 03:16:09     602467 2vkm_g2.bin\n",
      "2022-12-16 03:16:09     131126 2vvn_g1.bin\n",
      "2022-12-16 03:16:09     393547 2vvn_g2.bin\n",
      "2022-12-16 03:16:09     140406 2vw5_g1.bin\n",
      "2022-12-16 03:16:09     420067 2vw5_g2.bin\n",
      "2022-12-16 03:16:09     110198 2w4x_g1.bin\n",
      "2022-12-16 03:16:09     328267 2w4x_g2.bin\n",
      "2022-12-16 03:16:09     120862 2w66_g1.bin\n",
      "2022-12-16 03:16:09     361627 2w66_g2.bin\n",
      "2022-12-16 03:16:09     151534 2wbg_g1.bin\n",
      "2022-12-16 03:16:09     455227 2wbg_g2.bin\n",
      "2022-12-16 03:16:09     121670 2wca_g1.bin\n",
      "2022-12-16 03:16:09     364267 2wca_g2.bin\n",
      "2022-12-16 03:16:09     109102 2weg_g1.bin\n",
      "2022-12-16 03:16:09     324667 2weg_g2.bin\n",
      "2022-12-16 03:16:09     107558 2wer_g1.bin\n",
      "2022-12-16 03:16:09     319147 2wer_g2.bin\n",
      "2022-12-16 03:16:09     124190 2wn9_g1.bin\n",
      "2022-12-16 03:16:09     371227 2wn9_g2.bin\n",
      "2022-12-16 03:16:09     123694 2wnc_g1.bin\n",
      "2022-12-16 03:16:09     368827 2wnc_g2.bin\n",
      "2022-12-16 03:16:09     140774 2wtv_g1.bin\n",
      "2022-12-16 03:16:09     422827 2wtv_g2.bin\n",
      "2022-12-16 03:16:09     110318 2wvt_g1.bin\n",
      "2022-12-16 03:16:09     328507 2wvt_g2.bin\n",
      "2022-12-16 03:16:09     158846 2x00_g1.bin\n",
      "2022-12-16 03:16:09     477787 2x00_g2.bin\n",
      "2022-12-16 03:16:09     144206 2xb8_g1.bin\n",
      "2022-12-16 03:16:09     433147 2xb8_g2.bin\n",
      "2022-12-16 03:16:09     154790 2xbv_g1.bin\n",
      "2022-12-16 03:16:09     465067 2xbv_g2.bin\n",
      "2022-12-16 03:16:09     113262 2xdl_g1.bin\n",
      "2022-12-16 03:16:09     336187 2xdl_g2.bin\n",
      "2022-12-16 03:16:09     135438 2xii_g1.bin\n",
      "2022-12-16 03:16:09     406267 2xii_g2.bin\n",
      "2022-12-16 03:16:09     120510 2xj7_g1.bin\n",
      "2022-12-16 03:16:09     360667 2xj7_g2.bin\n",
      "2022-12-16 03:16:09     134350 2xnb_g1.bin\n",
      "2022-12-16 03:16:09     402427 2xnb_g2.bin\n",
      "2022-12-16 03:16:09     131054 2xys_g1.bin\n",
      "2022-12-16 03:16:09     391867 2xys_g2.bin\n",
      "2022-12-16 03:16:09     133030 2y5h_g1.bin\n",
      "2022-12-16 03:16:09     397867 2y5h_g2.bin\n",
      "2022-12-16 03:16:09     134686 2yfe_g1.bin\n",
      "2022-12-16 03:16:09     403867 2yfe_g2.bin\n",
      "2022-12-16 03:16:09     144470 2yge_g1.bin\n",
      "2022-12-16 03:16:09     432907 2yge_g2.bin\n",
      "2022-12-16 03:16:09     162430 2yki_g1.bin\n",
      "2022-12-16 03:16:09     489307 2yki_g2.bin\n",
      "2022-12-16 03:16:09     104518 2ymd_g1.bin\n",
      "2022-12-16 03:16:09     310507 2ymd_g2.bin\n",
      "2022-12-16 03:16:09     144134 2zb1_g1.bin\n",
      "2022-12-16 03:16:09     433387 2zb1_g2.bin\n",
      "2022-12-16 03:16:09     131854 2zcq_g1.bin\n",
      "2022-12-16 03:16:09     394747 2zcq_g2.bin\n",
      "2022-12-16 03:16:09     158694 2zcr_g1.bin\n",
      "2022-12-16 03:16:09     476227 2zcr_g2.bin\n",
      "2022-12-16 03:16:09     139758 2zda_g1.bin\n",
      "2022-12-16 03:16:09     418507 2zda_g2.bin\n",
      "2022-12-16 03:16:09     144438 2zy1_g1.bin\n",
      "2022-12-16 03:16:09     431947 2zy1_g2.bin\n",
      "2022-12-16 03:16:09     123038 3acw_g1.bin\n",
      "2022-12-16 03:16:09     367267 3acw_g2.bin\n",
      "2022-12-16 03:16:09     212398 3ag9_g1.bin\n",
      "2022-12-16 03:16:09     645307 3ag9_g2.bin\n",
      "2022-12-16 03:16:09     103990 3ao4_g1.bin\n",
      "2022-12-16 03:16:09     309067 3ao4_g2.bin\n",
      "2022-12-16 03:16:09     157430 3arp_g1.bin\n",
      "2022-12-16 03:16:09     470227 3arp_g2.bin\n",
      "2022-12-16 03:16:09     119670 3arq_g1.bin\n",
      "2022-12-16 03:16:09     355147 3arq_g2.bin\n",
      "2022-12-16 03:16:09     151070 3b1m_g1.bin\n",
      "2022-12-16 03:16:09     453427 3b1m_g2.bin\n",
      "2022-12-16 03:16:09     110302 3b27_g1.bin\n",
      "2022-12-16 03:16:09     327067 3b27_g2.bin\n",
      "2022-12-16 03:16:09     166638 3b5r_g1.bin\n",
      "2022-12-16 03:16:09     503227 3b5r_g2.bin\n",
      "2022-12-16 03:16:09     157774 3b65_g1.bin\n",
      "2022-12-16 03:16:09     475387 3b65_g2.bin\n",
      "2022-12-16 03:16:09     171686 3b68_g1.bin\n",
      "2022-12-16 03:16:09     518707 3b68_g2.bin\n",
      "2022-12-16 03:16:09     118846 3bgz_g1.bin\n",
      "2022-12-16 03:16:09     354907 3bgz_g2.bin\n",
      "2022-12-16 03:16:09     157926 3bv9_g1.bin\n",
      "2022-12-16 03:16:09     474667 3bv9_g2.bin\n",
      "2022-12-16 03:16:09     120470 3cj4_g1.bin\n",
      "2022-12-16 03:16:09     359947 3cj4_g2.bin\n",
      "2022-12-16 03:16:09     156046 3coy_g1.bin\n",
      "2022-12-16 03:16:09     469507 3coy_g2.bin\n",
      "2022-12-16 03:16:09     147694 3coz_g1.bin\n",
      "2022-12-16 03:16:09     443467 3coz_g2.bin\n",
      "2022-12-16 03:16:09     103966 3d4z_g1.bin\n",
      "2022-12-16 03:16:09     307627 3d4z_g2.bin\n",
      "2022-12-16 03:16:09     114382 3dd0_g1.bin\n",
      "2022-12-16 03:16:09     340987 3dd0_g2.bin\n",
      "2022-12-16 03:16:09      91670 3dx1_g1.bin\n",
      "2022-12-16 03:16:09     269707 3dx1_g2.bin\n",
      "2022-12-16 03:16:09     106230 3dx2_g1.bin\n",
      "2022-12-16 03:16:09     314827 3dx2_g2.bin\n",
      "2022-12-16 03:16:09     135726 3e5a_g1.bin\n",
      "2022-12-16 03:16:09     407107 3e5a_g2.bin\n",
      "2022-12-16 03:16:09     143518 3e92_g1.bin\n",
      "2022-12-16 03:16:09     430747 3e92_g2.bin\n",
      "2022-12-16 03:16:09     166350 3e93_g1.bin\n",
      "2022-12-16 03:16:09     500347 3e93_g2.bin\n",
      "2022-12-16 03:16:09      91582 3ebp_g1.bin\n",
      "2022-12-16 03:16:09     270307 3ebp_g2.bin\n",
      "2022-12-16 03:16:10     107062 3ehy_g1.bin\n",
      "2022-12-16 03:16:10     318307 3ehy_g2.bin\n",
      "2022-12-16 03:16:10     127374 3ejr_g1.bin\n",
      "2022-12-16 03:16:10     378547 3ejr_g2.bin\n",
      "2022-12-16 03:16:10     117214 3f3c_g1.bin\n",
      "2022-12-16 03:16:10     350107 3f3c_g2.bin\n",
      "2022-12-16 03:16:10     103070 3f3d_g1.bin\n",
      "2022-12-16 03:16:10     305827 3f3d_g2.bin\n",
      "2022-12-16 03:16:10     105446 3f3e_g1.bin\n",
      "2022-12-16 03:16:10     313387 3f3e_g2.bin\n",
      "2022-12-16 03:16:10      93102 3fcq_g1.bin\n",
      "2022-12-16 03:16:10     274747 3fcq_g2.bin\n",
      "2022-12-16 03:16:10     140606 3fur_g1.bin\n",
      "2022-12-16 03:16:10     422107 3fur_g2.bin\n",
      "2022-12-16 03:16:10     137134 3fv1_g1.bin\n",
      "2022-12-16 03:16:10     411067 3fv1_g2.bin\n",
      "2022-12-16 03:16:10     136214 3fv2_g1.bin\n",
      "2022-12-16 03:16:10     407947 3fv2_g2.bin\n",
      "2022-12-16 03:16:10     142526 3g0w_g1.bin\n",
      "2022-12-16 03:16:10     427867 3g0w_g2.bin\n",
      "2022-12-16 03:16:10      89614 3g2z_g1.bin\n",
      "2022-12-16 03:16:10     261907 3g2z_g2.bin\n",
      "2022-12-16 03:16:10      58294 3g31_g1.bin\n",
      "2022-12-16 03:16:10     166867 3g31_g2.bin\n",
      "2022-12-16 03:16:10     128846 3gbb_g1.bin\n",
      "2022-12-16 03:16:10     385147 3gbb_g2.bin\n",
      "2022-12-16 03:16:10     123358 3gc5_g1.bin\n",
      "2022-12-16 03:16:10     367387 3gc5_g2.bin\n",
      "2022-12-16 03:16:10     136494 3ge7_g1.bin\n",
      "2022-12-16 03:16:10     409147 3ge7_g2.bin\n",
      "2022-12-16 03:16:10     185190 3gnw_g1.bin\n",
      "2022-12-16 03:16:10     558907 3gnw_g2.bin\n",
      "2022-12-16 03:16:10      78622 3gr2_g1.bin\n",
      "2022-12-16 03:16:10     229027 3gr2_g2.bin\n",
      "2022-12-16 03:16:10      84838 3gv9_g1.bin\n",
      "2022-12-16 03:16:10     247867 3gv9_g2.bin\n",
      "2022-12-16 03:16:10      89878 3gy4_g1.bin\n",
      "2022-12-16 03:16:10     263947 3gy4_g2.bin\n",
      "2022-12-16 03:16:10     138598 3ivg_g1.bin\n",
      "2022-12-16 03:16:10     415147 3ivg_g2.bin\n",
      "2022-12-16 03:16:10      76686 3jvr_g1.bin\n",
      "2022-12-16 03:16:10     223507 3jvr_g2.bin\n",
      "2022-12-16 03:16:10      89102 3jvs_g1.bin\n",
      "2022-12-16 03:16:10     262267 3jvs_g2.bin\n",
      "2022-12-16 03:16:10     100974 3jya_g1.bin\n",
      "2022-12-16 03:16:10     299707 3jya_g2.bin\n",
      "2022-12-16 03:16:10     114678 3k5v_g1.bin\n",
      "2022-12-16 03:16:10     341707 3k5v_g2.bin\n",
      "2022-12-16 03:16:10      92894 3kgp_g1.bin\n",
      "2022-12-16 03:16:10     272947 3kgp_g2.bin\n",
      "2022-12-16 03:16:10     126678 3kr8_g1.bin\n",
      "2022-12-16 03:16:10     379147 3kr8_g2.bin\n",
      "2022-12-16 03:16:10     113214 3kwa_g1.bin\n",
      "2022-12-16 03:16:10     337627 3kwa_g2.bin\n",
      "2022-12-16 03:16:10      97894 3lka_g1.bin\n",
      "2022-12-16 03:16:10     290107 3lka_g2.bin\n",
      "2022-12-16 03:16:10      96982 3mss_g1.bin\n",
      "2022-12-16 03:16:10     286987 3mss_g2.bin\n",
      "2022-12-16 03:16:10     117406 3myg_g1.bin\n",
      "2022-12-16 03:16:10     350107 3myg_g2.bin\n",
      "2022-12-16 03:16:10     149854 3n76_g1.bin\n",
      "2022-12-16 03:16:10     449947 3n76_g2.bin\n",
      "2022-12-16 03:16:10     108062 3n7a_g1.bin\n",
      "2022-12-16 03:16:10     321307 3n7a_g2.bin\n",
      "2022-12-16 03:16:10     151990 3n86_g1.bin\n",
      "2022-12-16 03:16:10     456907 3n86_g2.bin\n",
      "2022-12-16 03:16:10      90838 3nq9_g1.bin\n",
      "2022-12-16 03:16:10     267787 3nq9_g2.bin\n",
      "2022-12-16 03:16:10     115894 3nx7_g1.bin\n",
      "2022-12-16 03:16:10     345547 3nx7_g2.bin\n",
      "2022-12-16 03:16:10     153294 3o9i_g1.bin\n",
      "2022-12-16 03:16:10     460027 3o9i_g2.bin\n",
      "2022-12-16 03:16:10     135974 3oe4_g1.bin\n",
      "2022-12-16 03:16:10     407467 3oe4_g2.bin\n",
      "2022-12-16 03:16:10     139398 3oe5_g1.bin\n",
      "2022-12-16 03:16:10     418027 3oe5_g2.bin\n",
      "2022-12-16 03:16:10     140374 3ozs_g1.bin\n",
      "2022-12-16 03:16:10     421387 3ozs_g2.bin\n",
      "2022-12-16 03:16:10     135334 3ozt_g1.bin\n",
      "2022-12-16 03:16:10     405547 3ozt_g2.bin\n",
      "2022-12-16 03:16:10     110710 3p5o_g1.bin\n",
      "2022-12-16 03:16:10     326947 3p5o_g2.bin\n",
      "2022-12-16 03:16:10     165638 3prs_g1.bin\n",
      "2022-12-16 03:16:10     497947 3prs_g2.bin\n",
      "2022-12-16 03:16:10     172246 3pww_g1.bin\n",
      "2022-12-16 03:16:10     518827 3pww_g2.bin\n",
      "2022-12-16 03:16:10     102942 3pyy_g1.bin\n",
      "2022-12-16 03:16:10     305947 3pyy_g2.bin\n",
      "2022-12-16 03:16:10     113574 3qgy_g1.bin\n",
      "2022-12-16 03:16:10     337987 3qgy_g2.bin\n",
      "2022-12-16 03:16:10      99358 3qqs_g1.bin\n",
      "2022-12-16 03:16:10     294427 3qqs_g2.bin\n",
      "2022-12-16 03:16:10      79822 3r88_g1.bin\n",
      "2022-12-16 03:16:10     233467 3r88_g2.bin\n",
      "2022-12-16 03:16:10     136734 3rlr_g1.bin\n",
      "2022-12-16 03:16:10     409627 3rlr_g2.bin\n",
      "2022-12-16 03:16:10     116462 3rr4_g1.bin\n",
      "2022-12-16 03:16:10     345787 3rr4_g2.bin\n",
      "2022-12-16 03:16:10     104814 3rsx_g1.bin\n",
      "2022-12-16 03:16:10     310987 3rsx_g2.bin\n",
      "2022-12-16 03:16:10     118870 3ryj_g1.bin\n",
      "2022-12-16 03:16:10     354187 3ryj_g2.bin\n",
      "2022-12-16 03:16:10     138974 3tsk_g1.bin\n",
      "2022-12-16 03:16:10     417307 3tsk_g2.bin\n",
      "2022-12-16 03:16:10      71646 3twp_g1.bin\n",
      "2022-12-16 03:16:10     208027 3twp_g2.bin\n",
      "2022-12-16 03:16:11      99254 3u5j_g1.bin\n",
      "2022-12-16 03:16:11     293707 3u5j_g2.bin\n",
      "2022-12-16 03:16:11     113974 3u8k_g1.bin\n",
      "2022-12-16 03:16:11     339547 3u8k_g2.bin\n",
      "2022-12-16 03:16:11     122222 3u8n_g1.bin\n",
      "2022-12-16 03:16:11     364987 3u8n_g2.bin\n",
      "2022-12-16 03:16:11     117054 3u9q_g1.bin\n",
      "2022-12-16 03:16:11     349147 3u9q_g2.bin\n",
      "2022-12-16 03:16:11     106110 3udh_g1.bin\n",
      "2022-12-16 03:16:11     314587 3udh_g2.bin\n",
      "2022-12-16 03:16:11     126918 3ueu_g1.bin\n",
      "2022-12-16 03:16:11     379627 3ueu_g2.bin\n",
      "2022-12-16 03:16:11     126806 3uev_g1.bin\n",
      "2022-12-16 03:16:11     379147 3uev_g2.bin\n",
      "2022-12-16 03:16:11     132894 3uew_g1.bin\n",
      "2022-12-16 03:16:11     398107 3uew_g2.bin\n",
      "2022-12-16 03:16:11     146342 3uex_g1.bin\n",
      "2022-12-16 03:16:11     440107 3uex_g2.bin\n",
      "2022-12-16 03:16:11     122462 3ui7_g1.bin\n",
      "2022-12-16 03:16:11     365467 3ui7_g2.bin\n",
      "2022-12-16 03:16:11     125630 3uo4_g1.bin\n",
      "2022-12-16 03:16:11     376027 3uo4_g2.bin\n",
      "2022-12-16 03:16:11     118166 3up2_g1.bin\n",
      "2022-12-16 03:16:11     352267 3up2_g2.bin\n",
      "2022-12-16 03:16:11     184062 3uri_g1.bin\n",
      "2022-12-16 03:16:11     552547 3uri_g2.bin\n",
      "2022-12-16 03:16:11     157958 3utu_g1.bin\n",
      "2022-12-16 03:16:11     475627 3utu_g2.bin\n",
      "2022-12-16 03:16:11     109118 3uuo_g1.bin\n",
      "2022-12-16 03:16:11     324187 3uuo_g2.bin\n",
      "2022-12-16 03:16:11     116910 3wtj_g1.bin\n",
      "2022-12-16 03:16:11     349627 3wtj_g2.bin\n",
      "2022-12-16 03:16:11     124310 3wz8_g1.bin\n",
      "2022-12-16 03:16:11     369187 3wz8_g2.bin\n",
      "2022-12-16 03:16:11     115014 3zdg_g1.bin\n",
      "2022-12-16 03:16:11     343147 3zdg_g2.bin\n",
      "2022-12-16 03:16:11     108870 3zso_g1.bin\n",
      "2022-12-16 03:16:11     323947 3zso_g2.bin\n",
      "2022-12-16 03:16:11      97726 3zsx_g1.bin\n",
      "2022-12-16 03:16:11     289507 3zsx_g2.bin\n",
      "2022-12-16 03:16:11      95870 3zt2_g1.bin\n",
      "2022-12-16 03:16:11     283867 3zt2_g2.bin\n",
      "2022-12-16 03:16:11      85334 4abg_g1.bin\n",
      "2022-12-16 03:16:11     250387 4abg_g2.bin\n",
      "2022-12-16 03:16:11      92390 4agn_g1.bin\n",
      "2022-12-16 03:16:11     271147 4agn_g2.bin\n",
      "2022-12-16 03:16:11      90334 4agp_g1.bin\n",
      "2022-12-16 03:16:11     265627 4agp_g2.bin\n",
      "2022-12-16 03:16:11      93766 4agq_g1.bin\n",
      "2022-12-16 03:16:11     275947 4agq_g2.bin\n",
      "2022-12-16 03:16:11      87038 4bkt_g1.bin\n",
      "2022-12-16 03:16:11     256987 4bkt_g2.bin\n",
      "2022-12-16 03:16:11     104406 4cig_g1.bin\n",
      "2022-12-16 03:16:11     310027 4cig_g2.bin\n",
      "2022-12-16 03:16:11     130230 4ciw_g1.bin\n",
      "2022-12-16 03:16:11     389707 4ciw_g2.bin\n",
      "2022-12-16 03:16:11      91566 4cr9_g1.bin\n",
      "2022-12-16 03:16:11     268747 4cr9_g2.bin\n",
      "2022-12-16 03:16:11     152518 4cra_g1.bin\n",
      "2022-12-16 03:16:11     458107 4cra_g2.bin\n",
      "2022-12-16 03:16:11     155422 4crc_g1.bin\n",
      "2022-12-16 03:16:11     467107 4crc_g2.bin\n",
      "2022-12-16 03:16:11     102750 4ddh_g1.bin\n",
      "2022-12-16 03:16:11     304027 4ddh_g2.bin\n",
      "2022-12-16 03:16:11      92830 4ddk_g1.bin\n",
      "2022-12-16 03:16:11     273067 4ddk_g2.bin\n",
      "2022-12-16 03:16:11     119534 4de1_g1.bin\n",
      "2022-12-16 03:16:11     355387 4de1_g2.bin\n",
      "2022-12-16 03:16:11     124822 4de2_g1.bin\n",
      "2022-12-16 03:16:11     371347 4de2_g2.bin\n",
      "2022-12-16 03:16:11     134942 4djv_g1.bin\n",
      "2022-12-16 03:16:11     403867 4djv_g2.bin\n",
      "2022-12-16 03:16:11     140814 4dld_g1.bin\n",
      "2022-12-16 03:16:11     421627 4dld_g2.bin\n",
      "2022-12-16 03:16:11     138262 4e5w_g1.bin\n",
      "2022-12-16 03:16:11     413707 4e5w_g2.bin\n",
      "2022-12-16 03:16:11     125110 4e6q_g1.bin\n",
      "2022-12-16 03:16:11     374347 4e6q_g2.bin\n",
      "2022-12-16 03:16:11     145070 4ea2_g1.bin\n",
      "2022-12-16 03:16:11     436027 4ea2_g2.bin\n",
      "2022-12-16 03:16:11     139390 4eo8_g1.bin\n",
      "2022-12-16 03:16:11     418267 4eo8_g2.bin\n",
      "2022-12-16 03:16:11     135654 4eor_g1.bin\n",
      "2022-12-16 03:16:11     407467 4eor_g2.bin\n",
      "2022-12-16 03:16:11     115310 4f09_g1.bin\n",
      "2022-12-16 03:16:11     343867 4f09_g2.bin\n",
      "2022-12-16 03:16:11     122982 4f2w_g1.bin\n",
      "2022-12-16 03:16:11     367147 4f2w_g2.bin\n",
      "2022-12-16 03:16:11     134470 4f3c_g1.bin\n",
      "2022-12-16 03:16:11     402667 4f3c_g2.bin\n",
      "2022-12-16 03:16:11     126398 4f9w_g1.bin\n",
      "2022-12-16 03:16:11     377947 4f9w_g2.bin\n",
      "2022-12-16 03:16:11     113238 4gfm_g1.bin\n",
      "2022-12-16 03:16:11     336907 4gfm_g2.bin\n",
      "2022-12-16 03:16:11     199118 4gid_g1.bin\n",
      "2022-12-16 03:16:11     601987 4gid_g2.bin\n",
      "2022-12-16 03:16:11      92454 4gkm_g1.bin\n",
      "2022-12-16 03:16:11     273067 4gkm_g2.bin\n",
      "2022-12-16 03:16:11     151158 4gr0_g1.bin\n",
      "2022-12-16 03:16:11     454987 4gr0_g2.bin\n",
      "2022-12-16 03:16:11     132142 4hge_g1.bin\n",
      "2022-12-16 03:16:11     395707 4hge_g2.bin\n",
      "2022-12-16 03:16:11     121606 4ih5_g1.bin\n",
      "2022-12-16 03:16:11     362107 4ih5_g2.bin\n",
      "2022-12-16 03:16:11     122694 4ih7_g1.bin\n",
      "2022-12-16 03:16:11     366187 4ih7_g2.bin\n",
      "2022-12-16 03:16:11     126398 4ivb_g1.bin\n",
      "2022-12-16 03:16:11     377947 4ivb_g2.bin\n",
      "2022-12-16 03:16:11     131902 4ivc_g1.bin\n",
      "2022-12-16 03:16:11     395227 4ivc_g2.bin\n",
      "2022-12-16 03:16:11     133310 4ivd_g1.bin\n",
      "2022-12-16 03:16:11     399067 4ivd_g2.bin\n",
      "2022-12-16 03:16:11     116654 4j21_g1.bin\n",
      "2022-12-16 03:16:12     347707 4j21_g2.bin\n",
      "2022-12-16 03:16:12     102070 4j28_g1.bin\n",
      "2022-12-16 03:16:12     303307 4j28_g2.bin\n",
      "2022-12-16 03:16:12     121294 4j3l_g1.bin\n",
      "2022-12-16 03:16:12     362107 4j3l_g2.bin\n",
      "2022-12-16 03:16:12     110086 4jfs_g1.bin\n",
      "2022-12-16 03:16:12     327787 4jfs_g2.bin\n",
      "2022-12-16 03:16:12     114918 4jia_g1.bin\n",
      "2022-12-16 03:16:12     342187 4jia_g2.bin\n",
      "2022-12-16 03:16:12      57518 4jsz_g1.bin\n",
      "2022-12-16 03:16:12     165307 4jsz_g2.bin\n",
      "2022-12-16 03:16:12     108574 4jxs_g1.bin\n",
      "2022-12-16 03:16:12     321307 4jxs_g2.bin\n",
      "2022-12-16 03:16:12     132430 4k18_g1.bin\n",
      "2022-12-16 03:16:12     396667 4k18_g2.bin\n",
      "2022-12-16 03:16:12     117062 4k77_g1.bin\n",
      "2022-12-16 03:16:12     348907 4k77_g2.bin\n",
      "2022-12-16 03:16:12      98998 4kz6_g1.bin\n",
      "2022-12-16 03:16:12     291427 4kz6_g2.bin\n",
      "2022-12-16 03:16:12     114654 4kzq_g1.bin\n",
      "2022-12-16 03:16:12     342307 4kzq_g2.bin\n",
      "2022-12-16 03:16:12     113446 4kzu_g1.bin\n",
      "2022-12-16 03:16:12     338347 4kzu_g2.bin\n",
      "2022-12-16 03:16:12      66782 4llx_g1.bin\n",
      "2022-12-16 03:16:12     192547 4llx_g2.bin\n",
      "2022-12-16 03:16:12      94046 4lzs_g1.bin\n",
      "2022-12-16 03:16:12     277147 4lzs_g2.bin\n",
      "2022-12-16 03:16:12      99486 4m0y_g1.bin\n",
      "2022-12-16 03:16:12     294427 4m0y_g2.bin\n",
      "2022-12-16 03:16:12     121942 4mgd_g1.bin\n",
      "2022-12-16 03:16:12     363787 4mgd_g2.bin\n",
      "2022-12-16 03:16:12     127014 4mme_g1.bin\n",
      "2022-12-16 03:16:12     380587 4mme_g2.bin\n",
      "2022-12-16 03:16:12     106342 4ogj_g1.bin\n",
      "2022-12-16 03:16:12     315307 4ogj_g2.bin\n",
      "2022-12-16 03:16:12      69078 4owm_g1.bin\n",
      "2022-12-16 03:16:12     200587 4owm_g2.bin\n",
      "2022-12-16 03:16:12     102766 4pcs_g1.bin\n",
      "2022-12-16 03:16:12     305467 4pcs_g2.bin\n",
      "2022-12-16 03:16:12     149454 4qac_g1.bin\n",
      "2022-12-16 03:16:12     450427 4qac_g2.bin\n",
      "2022-12-16 03:16:12      99742 4qd6_g1.bin\n",
      "2022-12-16 03:16:12     296227 4qd6_g2.bin\n",
      "2022-12-16 03:16:12     132998 4rfm_g1.bin\n",
      "2022-12-16 03:16:12     398827 4rfm_g2.bin\n",
      "2022-12-16 03:16:12     164750 4tmn_g1.bin\n",
      "2022-12-16 03:16:12     496267 4tmn_g2.bin\n",
      "2022-12-16 03:16:12     131558 4twp_g1.bin\n",
      "2022-12-16 03:16:12     393787 4twp_g2.bin\n",
      "2022-12-16 03:16:12     153750 4ty7_g1.bin\n",
      "2022-12-16 03:16:12     461707 4ty7_g2.bin\n",
      "2022-12-16 03:16:12     108910 4w9c_g1.bin\n",
      "2022-12-16 03:16:12     324667 4w9c_g2.bin\n",
      "2022-12-16 03:16:12     116686 4w9h_g1.bin\n",
      "2022-12-16 03:16:12     348667 4w9h_g2.bin\n",
      "2022-12-16 03:16:12     112398 4w9i_g1.bin\n",
      "2022-12-16 03:16:12     335227 4w9i_g2.bin\n",
      "2022-12-16 03:16:12     118358 4w9l_g1.bin\n",
      "2022-12-16 03:16:12     354187 4w9l_g2.bin\n",
      "2022-12-16 03:16:12     104486 4wiv_g1.bin\n",
      "2022-12-16 03:16:12     309547 4wiv_g2.bin\n",
      "2022-12-16 03:16:12      94350 5a7b_g1.bin\n",
      "2022-12-16 03:16:12     277507 5a7b_g2.bin\n",
      "2022-12-16 03:16:12      78670 5aba_g1.bin\n",
      "2022-12-16 03:16:12     229627 5aba_g2.bin\n",
      "2022-12-16 03:16:12      89350 5c28_g1.bin\n",
      "2022-12-16 03:16:12     262507 5c28_g2.bin\n",
      "2022-12-16 03:16:12     151966 5c2h_g1.bin\n",
      "2022-12-16 03:16:12     457627 5c2h_g2.bin\n",
      "2022-12-16 03:16:12     135526 5dwr_g1.bin\n",
      "2022-12-16 03:16:12     405547 5dwr_g2.bin\n",
      "2022-12-16 03:16:12     146790 5tmn_g1.bin\n",
      "2022-12-16 03:16:12     439747 5tmn_g2.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://{bucket}/preprocessed/graph_files_v2020_refined_core/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5d8c9",
   "metadata": {},
   "source": [
    "### 入力データセットの指定\n",
    "\n",
    "`1_make_potential_graphs`のノートブックでバイナリファイルを配置したのと同じS3 URIを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934cc994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#s3_input = sagemaker.inputs.TrainingInput(s3_data='<your S3 prefix of input binary files>')\n",
    "s3_input = sagemaker.inputs.TrainingInput(s3_data=f's3://{bucket}/preprocessed/graph_files_v2020_refined_core/')\n",
    "#s3_input_ft = sagemaker.inputs.TrainingInput(s3_data='<your S3 prefix of input binary files for fine tuning>') #option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c9685",
   "metadata": {},
   "source": [
    "### SageMaker Estimator Class\n",
    "Amazon SageMaker Estimatorを使用すると、CPUまたはGPUベースのインスタンスを使用して、Amazon SageMakerでシングルマシンを実行することができます。\n",
    "\n",
    "Estimatorを作成する際に、学習スクリプトのファイル名とIAM実行ロールの名前を渡します。`instance_count`と`instance_type`は、トレーニングジョブに使用されるAmazon SageMakerインスタンスの数と種類を決定します。`hyperparameters`パラメータは、`argparse`を使用して解析できるように、パラメータとしてトレーニングスクリプトに渡される値のディクショナリです。これらの値にアクセスする方法は、上記の`main.py`スクリプトで確認することができます。\n",
    "\n",
    "この例では、学習用インスタンスにml.p3.2xlargeを、PDBBind(v2020) core + generalデータセットを使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4710937c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"val_mae\", \"Regex\": \"val mae: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"val_r2\", \"Regex\": \"val r2: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"test_mae\", \"Regex\": \"test mae: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"test_r2\", \"Regex\": \"test r2: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"mae\", \"Regex\": \"mae ([0-9.]+).*$\"},\n",
    "    {\"Name\": \"r2\", \"Regex\": \"r2 ([0-9.]+).*$\"},\n",
    "]\n",
    "\n",
    "# Create estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"main.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    hyperparameters={\n",
    "        \"lr\":0.001,\n",
    "    },\n",
    "    metric_definitions=metric_definitions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41cae8",
   "metadata": {},
   "source": [
    "### Running the Training Job\n",
    "After you construct the Estimator object, fit it by using Amazon SageMaker. The [PDBBind](http://www.pdbbind.org.cn/) dataset is automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ac1ffd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-16 03:24:01 Starting - Starting the training job...\n",
      "2022-12-16 03:24:28 Starting - Preparing the instances for trainingProfilerReport-1671161041: InProgress\n",
      "............\n",
      "2022-12-16 03:26:20 Downloading - Downloading input data......\n",
      "2022-12-16 03:27:21 Training - Downloading the training image......\n",
      "2022-12-16 03:28:21 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-12-16 03:28:27,768 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-12-16 03:28:27,806 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-12-16 03:28:27,810 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-12-16 03:28:27,988 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting dgl-cu101\n",
      "  Downloading dgl_cu101-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (36.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting dgllife\n",
      "  Downloading dgllife-0.3.0-py3-none-any.whl (220 kB)\u001b[0m\n",
      "\u001b[34mCollecting rdkit-pypi\n",
      "  Downloading rdkit_pypi-2021.9.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (2.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.1->dgl-cu101->-r requirements.txt (line 1)) (4.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<1.0,>=0.22.2 in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (0.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (4.51.0)\u001b[0m\n",
      "\u001b[34mCollecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn<1.0,>=0.22.2->dgllife->-r requirements.txt (line 2)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from rdkit-pypi->-r requirements.txt (line 3)) (8.2.0)\u001b[0m\n",
      "\u001b[34mCollecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife->-r requirements.txt (line 2)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife->-r requirements.txt (line 2)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->dgllife->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->dgllife->-r requirements.txt (line 2)) (2021.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: py4j, hyperopt, rdkit-pypi, dgllife, dgl-cu101\u001b[0m\n",
      "\u001b[34mSuccessfully installed dgl-cu101-0.6.1 dgllife-0.3.0 hyperopt-0.2.7 py4j-0.10.9.7 rdkit-pypi-2021.9.4\u001b[0m\n",
      "\u001b[34m2022-12-16 03:28:39,373 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-12-16-03-24-01-215\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-03-24-01-215/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"lr\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-03-24-01-215/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-12-16-03-24-01-215\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-03-24-01-215/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--lr\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 main.py --lr 0.001\u001b[0m\n",
      "\u001b[34mmodel: PotentialNet\u001b[0m\n",
      "\u001b[34mdataset_option: PDBBind_refined_pocket_scaffold\u001b[0m\n",
      "\u001b[34mversion: v2015\u001b[0m\n",
      "\u001b[34mnum_workers: 8\u001b[0m\n",
      "\u001b[34msave_r2: \u001b[0m\n",
      "\u001b[34mtest_on_core: True\u001b[0m\n",
      "\u001b[34mmodel_dir: /opt/ml/model\u001b[0m\n",
      "\u001b[34mcurrent_host: algo-1\u001b[0m\n",
      "\u001b[34mhosts: ['algo-1']\u001b[0m\n",
      "\u001b[34mnum_gpus: 1\u001b[0m\n",
      "\u001b[34mfine_tune: False\u001b[0m\n",
      "\u001b[34mpretrained_model: \u001b[0m\n",
      "\u001b[34mlr: 0.001\u001b[0m\n",
      "\u001b[34mexp: PotentialNet_PDBBind_refined_pocket_scaffold\u001b[0m\n",
      "\u001b[34mdata_dir: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mdataset: PDBBind\u001b[0m\n",
      "\u001b[34msubset: refined\u001b[0m\n",
      "\u001b[34mload_binding_pocket: True\u001b[0m\n",
      "\u001b[34mremove_coreset_from_refinedset: True\u001b[0m\n",
      "\u001b[34mrandom_seed: 123\u001b[0m\n",
      "\u001b[34mfrac_train: 0.8\u001b[0m\n",
      "\u001b[34mfrac_val: 0.2\u001b[0m\n",
      "\u001b[34mfrac_test: 0.0\u001b[0m\n",
      "\u001b[34mbatch_size: 200\u001b[0m\n",
      "\u001b[34mshuffle: False\u001b[0m\n",
      "\u001b[34mmax_num_neighbors: 5\u001b[0m\n",
      "\u001b[34mdistance_bins: [1.5, 2.5, 3.5, 4.5]\u001b[0m\n",
      "\u001b[34mf_in: 44\u001b[0m\n",
      "\u001b[34mf_bond: 48\u001b[0m\n",
      "\u001b[34mf_gather: 48\u001b[0m\n",
      "\u001b[34mf_spatial: 48\u001b[0m\n",
      "\u001b[34mn_rows_fc: [48, 24]\u001b[0m\n",
      "\u001b[34mn_bond_conv_steps: 2\u001b[0m\n",
      "\u001b[34mn_spatial_conv_steps: 1\u001b[0m\n",
      "\u001b[34mdropouts: [0.25, 0.25, 0.25]\u001b[0m\n",
      "\u001b[34mnum_epochs: 200\u001b[0m\n",
      "\u001b[34mwd: 1e-05\u001b[0m\n",
      "\u001b[34mmetrics: ['r2', 'mae']\u001b[0m\n",
      "\u001b[34msplit: scaffold\u001b[0m\n",
      "\u001b[34m[]\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/train/5c2h_g1.bin', '/opt/ml/input/data/train/2c3i_g1.bin', '/opt/ml/input/data/train/3o9i_g1.bin', '/opt/ml/input/data/train/4ivb_g1.bin', '/opt/ml/input/data/train/4eo8_g1.bin', '/opt/ml/input/data/train/4w9i_g1.bin', '/opt/ml/input/data/train/3jvs_g1.bin', '/opt/ml/input/data/train/4mgd_g1.bin', '/opt/ml/input/data/train/3up2_g1.bin', '/opt/ml/input/data/train/4llx_g1.bin', '/opt/ml/input/data/train/1z9g_g1.bin', '/opt/ml/input/data/train/2xdl_g1.bin', '/opt/ml/input/data/train/2qnq_g1.bin', '/opt/ml/input/data/train/1oyt_g1.bin', '/opt/ml/input/data/train/3zt2_g1.bin', '/opt/ml/input/data/train/2xb8_g1.bin', '/opt/ml/input/data/train/2v7a_g1.bin', '/opt/ml/input/data/train/3arp_g1.bin', '/opt/ml/input/data/train/4tmn_g1.bin', '/opt/ml/input/data/train/4dld_g1.bin', '/opt/ml/input/data/train/1uto_g1.bin', '/opt/ml/input/data/train/4pcs_g1.bin', '/opt/ml/input/data/train/2cet_g1.bin', '/opt/ml/input/data/train/1u1b_g1.bin', '/opt/ml/input/data/train/3bgz_g1.bin', '/opt/ml/input/data/train/3ozt_g1.bin', '/opt/ml/input/data/train/4ivc_g1.bin', '/opt/ml/input/data/train/4j21_g1.bin', '/opt/ml/input/data/train/1qf1_g1.bin', '/opt/ml/input/data/train/3e92_g1.bin', '/opt/ml/input/data/train/2x00_g1.bin', '/opt/ml/input/data/train/4kz6_g1.bin', '/opt/ml/input/data/train/1q8u_g1.bin', '/opt/ml/input/data/train/3jvr_g1.bin', '/opt/ml/input/data/train/3bv9_g1.bin', '/opt/ml/input/data/train/3e93_g1.bin', '/opt/ml/input/data/train/2wtv_g1.bin', '/opt/ml/input/data/train/2zb1_g1.bin', '/opt/ml/input/data/train/4agp_g1.bin', '/opt/ml/input/data/train/3ivg_g1.bin', '/opt/ml/input/data/train/2w4x_g1.bin', '/opt/ml/input/data/train/3fv1_g1.bin', '/opt/ml/input/data/train/1nc3_g1.bin', '/opt/ml/input/data/train/1gpk_g1.bin', '/opt/ml/input/data/train/3ag9_g1.bin', '/opt/ml/input/data/train/3u8k_g1.bin', '/opt/ml/input/data/train/3qgy_g1.bin', '/opt/ml/input/data/train/4mme_g1.bin', '/opt/ml/input/data/train/1a30_g1.bin', '/opt/ml/input/data/train/3lka_g1.bin', '/opt/ml/input/data/train/3e5a_g1.bin', '/opt/ml/input/data/train/3b5r_g1.bin', '/opt/ml/input/data/train/1r5y_g1.bin', '/opt/ml/input/data/train/1vso_g1.bin', '/opt/ml/input/data/train/1p1q_g1.bin', '/opt/ml/input/data/train/3uew_g1.bin', '/opt/ml/input/data/train/2xj7_g1.bin', '/opt/ml/input/data/train/3b68_g1.bin', '/opt/ml/input/data/train/3ao4_g1.bin', '/opt/ml/input/data/train/3zsx_g1.bin', '/opt/ml/input/data/train/3dx1_g1.bin', '/opt/ml/input/data/train/1ps3_g1.bin', '/opt/ml/input/data/train/3udh_g1.bin', '/opt/ml/input/data/train/3kgp_g1.bin', '/opt/ml/input/data/train/1sqa_g1.bin', '/opt/ml/input/data/train/2vkm_g1.bin', '/opt/ml/input/data/train/3kwa_g1.bin', '/opt/ml/input/data/train/2wnc_g1.bin', '/opt/ml/input/data/train/4ciw_g1.bin', '/opt/ml/input/data/train/3b1m_g1.bin', '/opt/ml/input/data/train/3gbb_g1.bin', '/opt/ml/input/data/train/2y5h_g1.bin', '/opt/ml/input/data/train/4j3l_g1.bin', '/opt/ml/input/data/train/4wiv_g1.bin', '/opt/ml/input/data/train/3uex_g1.bin', '/opt/ml/input/data/train/4m0y_g1.bin', '/opt/ml/input/data/train/1owh_g1.bin', '/opt/ml/input/data/train/1o0h_g1.bin', '/opt/ml/input/data/train/2r9w_g1.bin', '/opt/ml/input/data/train/5aba_g1.bin', '/opt/ml/input/data/train/3uri_g1.bin', '/opt/ml/input/data/train/4cra_g1.bin', '/opt/ml/input/data/train/4de2_g1.bin', '/opt/ml/input/data/train/2w66_g1.bin', '/opt/ml/input/data/train/4agn_g1.bin', '/opt/ml/input/data/train/2ymd_g1.bin', '/opt/ml/input/data/train/4ih7_g1.bin', '/opt/ml/input/data/train/2v00_g1.bin', '/opt/ml/input/data/train/1e66_g1.bin', '/opt/ml/input/data/train/4de1_g1.bin', '/opt/ml/input/data/train/1eby_g1.bin', '/opt/ml/input/data/train/1k1i_g1.bin', '/opt/ml/input/data/train/3k5v_g1.bin', '/opt/ml/input/data/train/3fv2_g1.bin', '/opt/ml/input/data/train/3gc5_g1.bin', '/opt/ml/input/data/train/2p4y_g1.bin', '/opt/ml/input/data/train/3u8n_g1.bin', '/opt/ml/input/data/train/3arq_g1.bin', '/opt/ml/input/data/train/2wca_g1.bin', '/opt/ml/input/data/train/4rfm_g1.bin', '/opt/ml/input/data/train/3twp_g1.bin', '/opt/ml/input/data/train/5dwr_g1.bin', '/opt/ml/input/data/train/4gr0_g1.bin', '/opt/ml/input/data/train/3qqs_g1.bin', '/opt/ml/input/data/train/1yc1_g1.bin', '/opt/ml/input/data/train/4k18_g1.bin', '/opt/ml/input/data/train/5tmn_g1.bin', '/opt/ml/input/data/train/4cr9_g1.bin', '/opt/ml/input/data/train/4owm_g1.bin', '/opt/ml/input/data/train/1z6e_g1.bin', '/opt/ml/input/data/train/2vvn_g1.bin', '/opt/ml/input/data/train/3ge7_g1.bin', '/opt/ml/input/data/train/4hge_g1.bin', '/opt/ml/input/data/train/3rr4_g1.bin', '/opt/ml/input/data/train/3pyy_g1.bin', '/opt/ml/input/data/train/2fxs_g1.bin', '/opt/ml/input/data/train/4ivd_g1.bin', '/opt/ml/input/data/train/2yge_g1.bin', '/opt/ml/input/data/train/4kzq_g1.bin', '/opt/ml/input/data/train/4jsz_g1.bin', '/opt/ml/input/data/train/3n7a_g1.bin', '/opt/ml/input/data/train/4abg_g1.bin', '/opt/ml/input/data/train/1bzc_g1.bin', '/opt/ml/input/data/train/2al5_g1.bin', '/opt/ml/input/data/train/3b27_g1.bin', '/opt/ml/input/data/train/3oe5_g1.bin', '/opt/ml/input/data/train/4kzu_g1.bin', '/opt/ml/input/data/train/3gnw_g1.bin', '/opt/ml/input/data/train/3dx2_g1.bin', '/opt/ml/input/data/train/4cig_g1.bin', '/opt/ml/input/data/train/4twp_g1.bin', '/opt/ml/input/data/train/4lzs_g1.bin', '/opt/ml/input/data/train/3jya_g1.bin', '/opt/ml/input/data/train/4w9h_g1.bin', '/opt/ml/input/data/train/3zso_g1.bin', '/opt/ml/input/data/train/3fur_g1.bin', '/opt/ml/input/data/train/3uev_g1.bin', '/opt/ml/input/data/train/4jia_g1.bin', '/opt/ml/input/data/train/2brb_g1.bin', '/opt/ml/input/data/train/3b65_g1.bin', '/opt/ml/input/data/train/2zy1_g1.bin', '/opt/ml/input/data/train/3f3e_g1.bin', '/opt/ml/input/data/train/3acw_g1.bin', '/opt/ml/input/data/train/3mss_g1.bin', '/opt/ml/input/data/train/3nq9_g1.bin', '/opt/ml/input/data/train/3uo4_g1.bin', '/opt/ml/input/data/train/1s38_g1.bin', '/opt/ml/input/data/train/1gpn_g1.bin', '/opt/ml/input/data/train/1bcu_g1.bin', '/opt/ml/input/data/train/3cj4_g1.bin', '/opt/ml/input/data/train/2p15_g1.bin', '/opt/ml/input/data/train/3dd0_g1.bin', '/opt/ml/input/data/train/1syi_g1.bin', '/opt/ml/input/data/train/4w9c_g1.bin', '/opt/ml/input/data/train/3pww_g1.bin', '/opt/ml/input/data/train/2fvd_g1.bin', '/opt/ml/input/data/train/2hb1_g1.bin', '/opt/ml/input/data/train/2qbp_g1.bin', '/opt/ml/input/data/train/2yfe_g1.bin', '/opt/ml/input/data/train/4gfm_g1.bin', '/opt/ml/input/data/train/2qe4_g1.bin', '/opt/ml/input/data/train/4f3c_g1.bin', '/opt/ml/input/data/train/3p5o_g1.bin', '/opt/ml/input/data/train/4f9w_g1.bin', '/opt/ml/input/data/train/4gid_g1.bin', '/opt/ml/input/data/train/4k77_g1.bin', '/opt/ml/input/data/train/2zcq_g1.bin', '/opt/ml/input/data/train/1p1n_g1.bin', '/opt/ml/input/data/train/1nc1_g1.bin', '/opt/ml/input/data/train/2j7h_g1.bin', '/opt/ml/input/data/train/3rsx_g1.bin', '/opt/ml/input/data/train/3ui7_g1.bin', '/opt/ml/input/data/train/3oe4_g1.bin', '/opt/ml/input/data/train/2j78_g1.bin', '/opt/ml/input/data/train/3myg_g1.bin', '/opt/ml/input/data/train/3zdg_g1.bin', '/opt/ml/input/data/train/2xii_g1.bin', '/opt/ml/input/data/train/3ryj_g1.bin', '/opt/ml/input/data/train/4jxs_g1.bin', '/opt/ml/input/data/train/2pog_g1.bin', '/opt/ml/input/data/train/1w4o_g1.bin', '/opt/ml/input/data/train/5c28_g1.bin', '/opt/ml/input/data/train/2wn9_g1.bin', '/opt/ml/input/data/train/3u5j_g1.bin', '/opt/ml/input/data/train/4w9l_g1.bin', '/opt/ml/input/data/train/2zda_g1.bin', '/opt/ml/input/data/train/3g0w_g1.bin', '/opt/ml/input/data/train/1o3f_g1.bin', '/opt/ml/input/data/train/5a7b_g1.bin', '/opt/ml/input/data/train/3gy4_g1.bin', '/opt/ml/input/data/train/4ddk_g1.bin', '/opt/ml/input/data/train/4bkt_g1.bin', '/opt/ml/input/data/train/4qac_g1.bin', '/opt/ml/input/data/train/4f2w_g1.bin', '/opt/ml/input/data/train/4agq_g1.bin', '/opt/ml/input/data/train/4gkm_g1.bin', '/opt/ml/input/data/train/3coz_g1.bin', '/opt/ml/input/data/train/2weg_g1.bin', '/opt/ml/input/data/train/1g2k_g1.bin', '/opt/ml/input/data/train/2wer_g1.bin', '/opt/ml/input/data/train/4djv_g1.bin', '/opt/ml/input/data/train/2vw5_g1.bin', '/opt/ml/input/data/train/3kr8_g1.bin', '/opt/ml/input/data/train/3ueu_g1.bin', '/opt/ml/input/data/train/3r88_g1.bin', '/opt/ml/input/data/train/2cbv_g1.bin', '/opt/ml/input/data/train/1h23_g1.bin', '/opt/ml/input/data/train/3uuo_g1.bin', '/opt/ml/input/data/train/2xbv_g1.bin', '/opt/ml/input/data/train/3n86_g1.bin', '/opt/ml/input/data/train/2wbg_g1.bin', '/opt/ml/input/data/train/4ih5_g1.bin', '/opt/ml/input/data/train/3d4z_g1.bin', '/opt/ml/input/data/train/4f09_g1.bin', '/opt/ml/input/data/train/4e5w_g1.bin', '/opt/ml/input/data/train/3ehy_g1.bin', '/opt/ml/input/data/train/3ebp_g1.bin', '/opt/ml/input/data/train/1h22_g1.bin', '/opt/ml/input/data/train/4ddh_g1.bin', '/opt/ml/input/data/train/3rlr_g1.bin', '/opt/ml/input/data/train/3wz8_g1.bin', '/opt/ml/input/data/train/3g31_g1.bin', '/opt/ml/input/data/train/4jfs_g1.bin', '/opt/ml/input/data/train/3f3d_g1.bin', '/opt/ml/input/data/train/2zcr_g1.bin', '/opt/ml/input/data/train/1pxn_g1.bin', '/opt/ml/input/data/train/4crc_g1.bin', '/opt/ml/input/data/train/3u9q_g1.bin', '/opt/ml/input/data/train/2iwx_g1.bin', '/opt/ml/input/data/train/1mq6_g1.bin', '/opt/ml/input/data/train/1lpg_g1.bin', '/opt/ml/input/data/train/2br1_g1.bin', '/opt/ml/input/data/train/4ty7_g1.bin', '/opt/ml/input/data/train/2xys_g1.bin', '/opt/ml/input/data/train/3tsk_g1.bin', '/opt/ml/input/data/train/2qbq_g1.bin', '/opt/ml/input/data/train/3wtj_g1.bin', '/opt/ml/input/data/train/1ydr_g1.bin', '/opt/ml/input/data/train/2yki_g1.bin', '/opt/ml/input/data/train/1nvq_g1.bin', '/opt/ml/input/data/train/4ogj_g1.bin', '/opt/ml/input/data/train/2xnb_g1.bin', '/opt/ml/input/data/train/3prs_g1.bin', '/opt/ml/input/data/train/2wvt_g1.bin', '/opt/ml/input/data/train/3gv9_g1.bin', '/opt/ml/input/data/train/3fcq_g1.bin', '/opt/ml/input/data/train/3ejr_g1.bin', '/opt/ml/input/data/train/4e6q_g1.bin', '/opt/ml/input/data/train/1q8t_g1.bin', '/opt/ml/input/data/train/3coy_g1.bin', '/opt/ml/input/data/train/3f3c_g1.bin', '/opt/ml/input/data/train/1y6r_g1.bin', '/opt/ml/input/data/train/1z95_g1.bin', '/opt/ml/input/data/train/3nx7_g1.bin', '/opt/ml/input/data/train/4eor_g1.bin', '/opt/ml/input/data/train/4qd6_g1.bin', '/opt/ml/input/data/train/2qbr_g1.bin', '/opt/ml/input/data/train/3gr2_g1.bin', '/opt/ml/input/data/train/4ea2_g1.bin', '/opt/ml/input/data/train/3utu_g1.bin', '/opt/ml/input/data/train/1qkt_g1.bin', '/opt/ml/input/data/train/3n76_g1.bin', '/opt/ml/input/data/train/3ozs_g1.bin', '/opt/ml/input/data/train/4j28_g1.bin', '/opt/ml/input/data/train/3g2z_g1.bin', '/opt/ml/input/data/train/1ydt_g1.bin']\u001b[0m\n",
      "\u001b[34mData Loader\u001b[0m\n",
      "\u001b[34mg2_edge_dim : 8\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:45.834 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.036 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.036 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.037 algo-1:33 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.037 algo-1:33 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.038 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.0.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.0.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.1.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.1.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.2.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.2.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.039 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.3.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.3.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.4.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.linears.4.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.gru.weight_ih count_params:6912\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.gru.weight_hh count_params:6912\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.gru.bias_ih count_params:144\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.gru.bias_hh count_params:144\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.i_nn.weight count_params:4416\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.i_nn.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.j_nn.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_1_model.j_nn.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.0.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.0.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.1.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.1.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.040 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.2.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.2.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.3.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.3.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.4.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.4.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.5.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.5.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.6.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.6.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.7.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.7.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.8.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.8.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.041 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.9.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.9.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.10.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.10.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.11.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.11.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.12.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.linears.12.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.gru.weight_ih count_params:6912\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.gru.weight_hh count_params:6912\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.gru.bias_ih count_params:144\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.gru.bias_hh count_params:144\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.i_nn.weight count_params:4608\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.042 algo-1:33 INFO hook.py:584] name:stage_2_model.i_nn.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_2_model.j_nn.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_2_model.j_nn.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_3_model.layers.0.weight count_params:2304\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_3_model.layers.0.bias count_params:48\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_3_model.layers.1.weight count_params:1152\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_3_model.layers.1.bias count_params:24\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_3_model.out_layer.weight count_params:24\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:584] name:stage_3_model.out_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:586] Total Trainable Params: 87937\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.043 algo-1:33 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-12-16 03:28:46.045 algo-1:33 INFO hook.py:476] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34mepoch 1/200, training | loss 1.2672, r2 0.0312, mae 1.9660\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1146, mae 1.7366\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7366\u001b[0m\n",
      "\u001b[34mval r2: 0.1146\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1146, mae 1.7366\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7366\u001b[0m\n",
      "\u001b[34mtest r2: 0.1146\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 2/200, training | loss 1.0334, r2 0.0320, mae 1.7523\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1826, mae 1.7852\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7852\u001b[0m\n",
      "\u001b[34mval r2: 0.1826\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1826, mae 1.7852\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7852\u001b[0m\n",
      "\u001b[34mtest r2: 0.1826\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  2\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  2\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 3/200, training | loss 1.0698, r2 0.0267, mae 1.8057\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2405, mae 1.7533\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7533\u001b[0m\n",
      "\u001b[34mval r2: 0.2405\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2405, mae 1.7533\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7533\u001b[0m\n",
      "\u001b[34mtest r2: 0.2405\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  3\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  3\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 4/200, training | loss 0.9729, r2 0.1120, mae 1.7341\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2855, mae 1.7073\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7073\u001b[0m\n",
      "\u001b[34mval r2: 0.2855\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2855, mae 1.7073\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7073\u001b[0m\n",
      "\u001b[34mtest r2: 0.2855\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  4\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  4\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 5/200, training | loss 1.0075, r2 0.0157, mae 1.7663\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2103, mae 1.6987\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6987\u001b[0m\n",
      "\u001b[34mval r2: 0.2103\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2103, mae 1.6987\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6987\u001b[0m\n",
      "\u001b[34mtest r2: 0.2103\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 6/200, training | loss 1.0099, r2 0.0026, mae 1.7717\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1294, mae 1.6931\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6931\u001b[0m\n",
      "\u001b[34mval r2: 0.1294\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1294, mae 1.6931\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6931\u001b[0m\n",
      "\u001b[34mtest r2: 0.1294\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 7/200, training | loss 0.9740, r2 0.0392, mae 1.7260\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1201, mae 1.6905\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6905\u001b[0m\n",
      "\u001b[34mval r2: 0.1201\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1201, mae 1.6905\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6905\u001b[0m\n",
      "\u001b[34mtest r2: 0.1201\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 8/200, training | loss 0.9807, r2 0.0256, mae 1.7416\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1370, mae 1.6880\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6880\u001b[0m\n",
      "\u001b[34mval r2: 0.1370\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1370, mae 1.6880\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6880\u001b[0m\n",
      "\u001b[34mtest r2: 0.1370\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 9/200, training | loss 0.9675, r2 0.0763, mae 1.7282\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1735, mae 1.6860\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6860\u001b[0m\n",
      "\u001b[34mval r2: 0.1735\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1735, mae 1.6860\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6860\u001b[0m\n",
      "\u001b[34mtest r2: 0.1735\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 10/200, training | loss 0.9708, r2 0.0708, mae 1.7343\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2097, mae 1.6886\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6886\u001b[0m\n",
      "\u001b[34mval r2: 0.2097\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2097, mae 1.6886\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6886\u001b[0m\n",
      "\u001b[34mtest r2: 0.2097\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 11/200, training | loss 0.9732, r2 0.0636, mae 1.7358\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2266, mae 1.6926\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6926\u001b[0m\n",
      "\u001b[34mval r2: 0.2266\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2266, mae 1.6926\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6926\u001b[0m\n",
      "\u001b[34mtest r2: 0.2266\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 12/200, training | loss 0.9671, r2 0.0828, mae 1.7345\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2465, mae 1.6926\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6926\u001b[0m\n",
      "\u001b[34mval r2: 0.2465\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2465, mae 1.6926\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6926\u001b[0m\n",
      "\u001b[34mtest r2: 0.2465\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 13/200, training | loss 0.9490, r2 0.1319, mae 1.7065\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2649, mae 1.6966\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6966\u001b[0m\n",
      "\u001b[34mval r2: 0.2649\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2649, mae 1.6966\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6966\u001b[0m\n",
      "\u001b[34mtest r2: 0.2649\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 14/200, training | loss 0.9607, r2 0.1283, mae 1.7160\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2532, mae 1.7008\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7008\u001b[0m\n",
      "\u001b[34mval r2: 0.2532\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2532, mae 1.7008\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7008\u001b[0m\n",
      "\u001b[34mtest r2: 0.2532\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 15/200, training | loss 0.9507, r2 0.1503, mae 1.6784\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2372, mae 1.6910\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6910\u001b[0m\n",
      "\u001b[34mval r2: 0.2372\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2372, mae 1.6910\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6910\u001b[0m\n",
      "\u001b[34mtest r2: 0.2372\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 16/200, training | loss 0.9470, r2 0.1485, mae 1.7077\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2151, mae 1.6812\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6812\u001b[0m\n",
      "\u001b[34mval r2: 0.2151\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2151, mae 1.6812\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6812\u001b[0m\n",
      "\u001b[34mtest r2: 0.2151\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 17/200, training | loss 0.9408, r2 0.1417, mae 1.6907\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2006, mae 1.6670\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6670\u001b[0m\n",
      "\u001b[34mval r2: 0.2006\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2006, mae 1.6670\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6670\u001b[0m\n",
      "\u001b[34mtest r2: 0.2006\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 18/200, training | loss 0.9207, r2 0.2143, mae 1.6732\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1852, mae 1.6593\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6593\u001b[0m\n",
      "\u001b[34mval r2: 0.1852\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1852, mae 1.6593\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6593\u001b[0m\n",
      "\u001b[34mtest r2: 0.1852\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 19/200, training | loss 0.9304, r2 0.1486, mae 1.6872\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1766, mae 1.6527\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6527\u001b[0m\n",
      "\u001b[34mval r2: 0.1766\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1766, mae 1.6527\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6527\u001b[0m\n",
      "\u001b[34mtest r2: 0.1766\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 20/200, training | loss 0.9395, r2 0.0989, mae 1.6969\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1776, mae 1.6565\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6565\u001b[0m\n",
      "\u001b[34mval r2: 0.1776\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1776, mae 1.6565\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6565\u001b[0m\n",
      "\u001b[34mtest r2: 0.1776\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 21/200, training | loss 0.9371, r2 0.1158, mae 1.7020\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1821, mae 1.6679\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6679\u001b[0m\n",
      "\u001b[34mval r2: 0.1821\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1821, mae 1.6679\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6679\u001b[0m\n",
      "\u001b[34mtest r2: 0.1821\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 22/200, training | loss 0.9454, r2 0.1069, mae 1.6931\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1852, mae 1.6756\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6756\u001b[0m\n",
      "\u001b[34mval r2: 0.1852\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1852, mae 1.6756\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6756\u001b[0m\n",
      "\u001b[34mtest r2: 0.1852\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 23/200, training | loss 0.9604, r2 0.0823, mae 1.7079\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1831, mae 1.6695\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6695\u001b[0m\n",
      "\u001b[34mval r2: 0.1831\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1831, mae 1.6695\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6695\u001b[0m\n",
      "\u001b[34mtest r2: 0.1831\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 24/200, training | loss 0.9294, r2 0.1193, mae 1.6878\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1761, mae 1.6558\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6558\u001b[0m\n",
      "\u001b[34mval r2: 0.1761\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1761, mae 1.6558\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6558\u001b[0m\n",
      "\u001b[34mtest r2: 0.1761\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 25/200, training | loss 0.9132, r2 0.1535, mae 1.6452\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1595, mae 1.6422\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6422\u001b[0m\n",
      "\u001b[34mval r2: 0.1595\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1595, mae 1.6422\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6422\u001b[0m\n",
      "\u001b[34mtest r2: 0.1595\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 26/200, training | loss 0.9100, r2 0.1372, mae 1.6773\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1406, mae 1.6320\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6320\u001b[0m\n",
      "\u001b[34mval r2: 0.1406\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1406, mae 1.6320\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6320\u001b[0m\n",
      "\u001b[34mtest r2: 0.1406\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 27/200, training | loss 0.9184, r2 0.1023, mae 1.6803\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1147, mae 1.6337\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6337\u001b[0m\n",
      "\u001b[34mval r2: 0.1147\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1147, mae 1.6337\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6337\u001b[0m\n",
      "\u001b[34mtest r2: 0.1147\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 28/200, training | loss 0.8987, r2 0.1267, mae 1.6766\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1234, mae 1.6393\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6393\u001b[0m\n",
      "\u001b[34mval r2: 0.1234\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1234, mae 1.6393\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6393\u001b[0m\n",
      "\u001b[34mtest r2: 0.1234\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 29/200, training | loss 0.8766, r2 0.1759, mae 1.6553\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1447, mae 1.6461\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6461\u001b[0m\n",
      "\u001b[34mval r2: 0.1447\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1447, mae 1.6461\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6461\u001b[0m\n",
      "\u001b[34mtest r2: 0.1447\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 30/200, training | loss 0.8858, r2 0.1755, mae 1.6521\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1456, mae 1.6374\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6374\u001b[0m\n",
      "\u001b[34mval r2: 0.1456\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1456, mae 1.6374\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6374\u001b[0m\n",
      "\u001b[34mtest r2: 0.1456\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 31/200, training | loss 0.8638, r2 0.2028, mae 1.6458\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1444, mae 1.6165\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6165\u001b[0m\n",
      "\u001b[34mval r2: 0.1444\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1444, mae 1.6165\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6165\u001b[0m\n",
      "\u001b[34mtest r2: 0.1444\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 32/200, training | loss 0.8873, r2 0.1410, mae 1.6428\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1511, mae 1.6102\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6102\u001b[0m\n",
      "\u001b[34mval r2: 0.1511\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1511, mae 1.6102\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6102\u001b[0m\n",
      "\u001b[34mtest r2: 0.1511\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 33/200, training | loss 0.8656, r2 0.1901, mae 1.6523\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1752, mae 1.6247\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6247\u001b[0m\n",
      "\u001b[34mval r2: 0.1752\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1752, mae 1.6247\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6247\u001b[0m\n",
      "\u001b[34mtest r2: 0.1752\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 34/200, training | loss 0.8654, r2 0.2152, mae 1.6427\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1610, mae 1.6115\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6115\u001b[0m\n",
      "\u001b[34mval r2: 0.1610\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1610, mae 1.6115\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6115\u001b[0m\n",
      "\u001b[34mtest r2: 0.1610\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 35/200, training | loss 0.8440, r2 0.2118, mae 1.6139\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1273, mae 1.5921\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5921\u001b[0m\n",
      "\u001b[34mval r2: 0.1273\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1273, mae 1.5921\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5921\u001b[0m\n",
      "\u001b[34mtest r2: 0.1273\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 36/200, training | loss 0.8656, r2 0.1494, mae 1.6441\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1334, mae 1.5918\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5918\u001b[0m\n",
      "\u001b[34mval r2: 0.1334\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1334, mae 1.5918\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5918\u001b[0m\n",
      "\u001b[34mtest r2: 0.1334\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 37/200, training | loss 0.8083, r2 0.2444, mae 1.5977\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1720, mae 1.6053\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6053\u001b[0m\n",
      "\u001b[34mval r2: 0.1720\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1720, mae 1.6053\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6053\u001b[0m\n",
      "\u001b[34mtest r2: 0.1720\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 38/200, training | loss 0.7929, r2 0.2772, mae 1.5524\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1761, mae 1.5922\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5922\u001b[0m\n",
      "\u001b[34mval r2: 0.1761\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1761, mae 1.5922\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5922\u001b[0m\n",
      "\u001b[34mtest r2: 0.1761\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 39/200, training | loss 0.8503, r2 0.1793, mae 1.6442\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1230, mae 1.5706\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5706\u001b[0m\n",
      "\u001b[34mval r2: 0.1230\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1230, mae 1.5706\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5706\u001b[0m\n",
      "\u001b[34mtest r2: 0.1230\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 40/200, training | loss 0.8078, r2 0.2088, mae 1.6023\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1493, mae 1.5640\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5640\u001b[0m\n",
      "\u001b[34mval r2: 0.1493\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1493, mae 1.5640\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5640\u001b[0m\n",
      "\u001b[34mtest r2: 0.1493\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 41/200, training | loss 0.8324, r2 0.1747, mae 1.6186\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1965, mae 1.5729\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5729\u001b[0m\n",
      "\u001b[34mval r2: 0.1965\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1965, mae 1.5729\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5729\u001b[0m\n",
      "\u001b[34mtest r2: 0.1965\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 42/200, training | loss 0.7984, r2 0.2534, mae 1.5732\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1362, mae 1.5611\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5611\u001b[0m\n",
      "\u001b[34mval r2: 0.1362\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1362, mae 1.5611\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5611\u001b[0m\n",
      "\u001b[34mtest r2: 0.1362\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 43/200, training | loss 0.7907, r2 0.2252, mae 1.5975\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1345, mae 1.5523\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5523\u001b[0m\n",
      "\u001b[34mval r2: 0.1345\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1345, mae 1.5523\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5523\u001b[0m\n",
      "\u001b[34mtest r2: 0.1345\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 44/200, training | loss 0.7605, r2 0.2522, mae 1.5293\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1747, mae 1.5538\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5538\u001b[0m\n",
      "\u001b[34mval r2: 0.1747\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1747, mae 1.5538\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5538\u001b[0m\n",
      "\u001b[34mtest r2: 0.1747\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 45/200, training | loss 0.8042, r2 0.2327, mae 1.5902\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1337, mae 1.5682\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5682\u001b[0m\n",
      "\u001b[34mval r2: 0.1337\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1337, mae 1.5682\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5682\u001b[0m\n",
      "\u001b[34mtest r2: 0.1337\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 46/200, training | loss 0.7752, r2 0.2273, mae 1.5680\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1474, mae 1.5634\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5634\u001b[0m\n",
      "\u001b[34mval r2: 0.1474\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1474, mae 1.5634\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5634\u001b[0m\n",
      "\u001b[34mtest r2: 0.1474\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 47/200, training | loss 0.7565, r2 0.2505, mae 1.5613\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1872, mae 1.5477\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5477\u001b[0m\n",
      "\u001b[34mval r2: 0.1872\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1872, mae 1.5477\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5477\u001b[0m\n",
      "\u001b[34mtest r2: 0.1872\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 48/200, training | loss 0.7633, r2 0.2651, mae 1.5254\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1314, mae 1.5599\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5599\u001b[0m\n",
      "\u001b[34mval r2: 0.1314\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1314, mae 1.5599\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5599\u001b[0m\n",
      "\u001b[34mtest r2: 0.1314\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 49/200, training | loss 0.7631, r2 0.2359, mae 1.5621\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1545, mae 1.5391\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5391\u001b[0m\n",
      "\u001b[34mval r2: 0.1545\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1545, mae 1.5391\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5391\u001b[0m\n",
      "\u001b[34mtest r2: 0.1545\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 50/200, training | loss 0.7545, r2 0.2458, mae 1.5481\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1980, mae 1.5433\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5433\u001b[0m\n",
      "\u001b[34mval r2: 0.1980\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1980, mae 1.5433\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5433\u001b[0m\n",
      "\u001b[34mtest r2: 0.1980\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 51/200, training | loss 0.7524, r2 0.2915, mae 1.5224\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1383, mae 1.5333\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5333\u001b[0m\n",
      "\u001b[34mval r2: 0.1383\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1383, mae 1.5333\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5333\u001b[0m\n",
      "\u001b[34mtest r2: 0.1383\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 52/200, training | loss 0.7550, r2 0.2454, mae 1.5517\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1511, mae 1.5252\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5252\u001b[0m\n",
      "\u001b[34mval r2: 0.1511\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1511, mae 1.5252\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5252\u001b[0m\n",
      "\u001b[34mtest r2: 0.1511\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 53/200, training | loss 0.7272, r2 0.2805, mae 1.5264\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2091, mae 1.5477\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5477\u001b[0m\n",
      "\u001b[34mval r2: 0.2091\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2091, mae 1.5477\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5477\u001b[0m\n",
      "\u001b[34mtest r2: 0.2091\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 54/200, training | loss 0.7695, r2 0.2795, mae 1.5264\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1258, mae 1.5719\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5719\u001b[0m\n",
      "\u001b[34mval r2: 0.1258\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1258, mae 1.5719\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5719\u001b[0m\n",
      "\u001b[34mtest r2: 0.1258\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 55/200, training | loss 0.7592, r2 0.2461, mae 1.5676\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1678, mae 1.5614\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5614\u001b[0m\n",
      "\u001b[34mval r2: 0.1678\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1678, mae 1.5614\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5614\u001b[0m\n",
      "\u001b[34mtest r2: 0.1678\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 56/200, training | loss 0.7267, r2 0.2853, mae 1.5173\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1814, mae 1.5552\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5552\u001b[0m\n",
      "\u001b[34mval r2: 0.1814\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1814, mae 1.5552\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5552\u001b[0m\n",
      "\u001b[34mtest r2: 0.1814\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 57/200, training | loss 0.6923, r2 0.3209, mae 1.4631\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1567, mae 1.5551\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5551\u001b[0m\n",
      "\u001b[34mval r2: 0.1567\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1567, mae 1.5551\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5551\u001b[0m\n",
      "\u001b[34mtest r2: 0.1567\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 58/200, training | loss 0.6727, r2 0.3355, mae 1.4559\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1791, mae 1.5417\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5417\u001b[0m\n",
      "\u001b[34mval r2: 0.1791\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1791, mae 1.5417\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5417\u001b[0m\n",
      "\u001b[34mtest r2: 0.1791\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 59/200, training | loss 0.6811, r2 0.3320, mae 1.4341\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2064, mae 1.5544\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5544\u001b[0m\n",
      "\u001b[34mval r2: 0.2064\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2064, mae 1.5544\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5544\u001b[0m\n",
      "\u001b[34mtest r2: 0.2064\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 60/200, training | loss 0.6996, r2 0.3304, mae 1.4715\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1424, mae 1.5900\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5900\u001b[0m\n",
      "\u001b[34mval r2: 0.1424\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1424, mae 1.5900\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5900\u001b[0m\n",
      "\u001b[34mtest r2: 0.1424\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 61/200, training | loss 0.7382, r2 0.2577, mae 1.5364\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1666, mae 1.5750\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5750\u001b[0m\n",
      "\u001b[34mval r2: 0.1666\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1666, mae 1.5750\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5750\u001b[0m\n",
      "\u001b[34mtest r2: 0.1666\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 62/200, training | loss 0.6301, r2 0.3811, mae 1.4106\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1595, mae 1.5770\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5770\u001b[0m\n",
      "\u001b[34mval r2: 0.1595\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1595, mae 1.5770\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5770\u001b[0m\n",
      "\u001b[34mtest r2: 0.1595\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 63/200, training | loss 0.6892, r2 0.3099, mae 1.4717\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1921, mae 1.5647\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5647\u001b[0m\n",
      "\u001b[34mval r2: 0.1921\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1921, mae 1.5647\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5647\u001b[0m\n",
      "\u001b[34mtest r2: 0.1921\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 64/200, training | loss 0.6661, r2 0.3642, mae 1.4144\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1398, mae 1.5777\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5777\u001b[0m\n",
      "\u001b[34mval r2: 0.1398\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1398, mae 1.5777\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5777\u001b[0m\n",
      "\u001b[34mtest r2: 0.1398\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 65/200, training | loss 0.6638, r2 0.3388, mae 1.4577\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1528, mae 1.5687\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5687\u001b[0m\n",
      "\u001b[34mval r2: 0.1528\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1528, mae 1.5687\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5687\u001b[0m\n",
      "\u001b[34mtest r2: 0.1528\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 66/200, training | loss 0.6834, r2 0.3160, mae 1.4653\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1914, mae 1.5884\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5884\u001b[0m\n",
      "\u001b[34mval r2: 0.1914\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1914, mae 1.5884\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5884\u001b[0m\n",
      "\u001b[34mtest r2: 0.1914\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 67/200, training | loss 0.6759, r2 0.3672, mae 1.4036\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1097, mae 1.6681\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6681\u001b[0m\n",
      "\u001b[34mval r2: 0.1097\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1097, mae 1.6681\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6681\u001b[0m\n",
      "\u001b[34mtest r2: 0.1097\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 68/200, training | loss 0.6302, r2 0.3768, mae 1.4188\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1390, mae 1.6360\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6360\u001b[0m\n",
      "\u001b[34mval r2: 0.1390\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1390, mae 1.6360\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6360\u001b[0m\n",
      "\u001b[34mtest r2: 0.1390\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 69/200, training | loss 0.6334, r2 0.3715, mae 1.4186\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2066, mae 1.6606\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6606\u001b[0m\n",
      "\u001b[34mval r2: 0.2066\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2066, mae 1.6606\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6606\u001b[0m\n",
      "\u001b[34mtest r2: 0.2066\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 70/200, training | loss 0.7005, r2 0.3867, mae 1.4447\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1364, mae 1.6323\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6323\u001b[0m\n",
      "\u001b[34mval r2: 0.1364\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1364, mae 1.6323\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6323\u001b[0m\n",
      "\u001b[34mtest r2: 0.1364\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 71/200, training | loss 0.5993, r2 0.4043, mae 1.3686\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1256, mae 1.6432\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6432\u001b[0m\n",
      "\u001b[34mval r2: 0.1256\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1256, mae 1.6432\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6432\u001b[0m\n",
      "\u001b[34mtest r2: 0.1256\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 72/200, training | loss 0.6077, r2 0.3991, mae 1.3898\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2065, mae 1.6255\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6255\u001b[0m\n",
      "\u001b[34mval r2: 0.2065\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2065, mae 1.6255\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6255\u001b[0m\n",
      "\u001b[34mtest r2: 0.2065\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 73/200, training | loss 0.6499, r2 0.3979, mae 1.3721\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1838, mae 1.6080\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6080\u001b[0m\n",
      "\u001b[34mval r2: 0.1838\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1838, mae 1.6080\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6080\u001b[0m\n",
      "\u001b[34mtest r2: 0.1838\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 74/200, training | loss 0.6579, r2 0.3625, mae 1.4335\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1132, mae 1.6693\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6693\u001b[0m\n",
      "\u001b[34mval r2: 0.1132\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1132, mae 1.6693\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6693\u001b[0m\n",
      "\u001b[34mtest r2: 0.1132\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 75/200, training | loss 0.6388, r2 0.3675, mae 1.4510\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1286, mae 1.6553\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6553\u001b[0m\n",
      "\u001b[34mval r2: 0.1286\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1286, mae 1.6553\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6553\u001b[0m\n",
      "\u001b[34mtest r2: 0.1286\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 76/200, training | loss 0.6236, r2 0.3759, mae 1.4069\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2055, mae 1.6394\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6394\u001b[0m\n",
      "\u001b[34mval r2: 0.2055\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2055, mae 1.6394\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6394\u001b[0m\n",
      "\u001b[34mtest r2: 0.2055\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 77/200, training | loss 0.6540, r2 0.3950, mae 1.4144\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1888, mae 1.6188\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6188\u001b[0m\n",
      "\u001b[34mval r2: 0.1888\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1888, mae 1.6188\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6188\u001b[0m\n",
      "\u001b[34mtest r2: 0.1888\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 78/200, training | loss 0.6051, r2 0.4271, mae 1.3709\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.0985, mae 1.7312\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7312\u001b[0m\n",
      "\u001b[34mval r2: 0.0985\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.0985, mae 1.7312\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7312\u001b[0m\n",
      "\u001b[34mtest r2: 0.0985\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 79/200, training | loss 0.7027, r2 0.3188, mae 1.5032\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1754, mae 1.5960\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5960\u001b[0m\n",
      "\u001b[34mval r2: 0.1754\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1754, mae 1.5960\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5960\u001b[0m\n",
      "\u001b[34mtest r2: 0.1754\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 80/200, training | loss 0.5664, r2 0.4489, mae 1.3151\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2300, mae 1.6142\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6142\u001b[0m\n",
      "\u001b[34mval r2: 0.2300\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2300, mae 1.6142\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6142\u001b[0m\n",
      "\u001b[34mtest r2: 0.2300\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 81/200, training | loss 0.6119, r2 0.4551, mae 1.3422\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2017, mae 1.5760\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5760\u001b[0m\n",
      "\u001b[34mval r2: 0.2017\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2017, mae 1.5760\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5760\u001b[0m\n",
      "\u001b[34mtest r2: 0.2017\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 82/200, training | loss 0.6287, r2 0.3938, mae 1.3862\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1243, mae 1.6898\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6898\u001b[0m\n",
      "\u001b[34mval r2: 0.1243\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1243, mae 1.6898\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6898\u001b[0m\n",
      "\u001b[34mtest r2: 0.1243\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 83/200, training | loss 0.6483, r2 0.3725, mae 1.4274\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1888, mae 1.5627\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5627\u001b[0m\n",
      "\u001b[34mval r2: 0.1888\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1888, mae 1.5627\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5627\u001b[0m\n",
      "\u001b[34mtest r2: 0.1888\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 84/200, training | loss 0.5964, r2 0.4192, mae 1.3705\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2249, mae 1.5642\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5642\u001b[0m\n",
      "\u001b[34mval r2: 0.2249\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2249, mae 1.5642\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5642\u001b[0m\n",
      "\u001b[34mtest r2: 0.2249\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 85/200, training | loss 0.5821, r2 0.4536, mae 1.3189\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2117, mae 1.5689\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5689\u001b[0m\n",
      "\u001b[34mval r2: 0.2117\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2117, mae 1.5689\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5689\u001b[0m\n",
      "\u001b[34mtest r2: 0.2117\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 86/200, training | loss 0.5788, r2 0.4435, mae 1.3286\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1537, mae 1.6505\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6505\u001b[0m\n",
      "\u001b[34mval r2: 0.1537\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1537, mae 1.6505\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6505\u001b[0m\n",
      "\u001b[34mtest r2: 0.1537\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 87/200, training | loss 0.5895, r2 0.4229, mae 1.3642\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1727, mae 1.6169\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6169\u001b[0m\n",
      "\u001b[34mval r2: 0.1727\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1727, mae 1.6169\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6169\u001b[0m\n",
      "\u001b[34mtest r2: 0.1727\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 88/200, training | loss 0.5950, r2 0.4054, mae 1.3751\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2256, mae 1.5828\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5828\u001b[0m\n",
      "\u001b[34mval r2: 0.2256\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2256, mae 1.5828\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5828\u001b[0m\n",
      "\u001b[34mtest r2: 0.2256\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 89/200, training | loss 0.5784, r2 0.4564, mae 1.3209\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2135, mae 1.5768\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5768\u001b[0m\n",
      "\u001b[34mval r2: 0.2135\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2135, mae 1.5768\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5768\u001b[0m\n",
      "\u001b[34mtest r2: 0.2135\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 90/200, training | loss 0.5723, r2 0.4407, mae 1.3187\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1708, mae 1.6283\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6283\u001b[0m\n",
      "\u001b[34mval r2: 0.1708\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1708, mae 1.6283\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6283\u001b[0m\n",
      "\u001b[34mtest r2: 0.1708\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 91/200, training | loss 0.5530, r2 0.4535, mae 1.3117\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1676, mae 1.6499\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6499\u001b[0m\n",
      "\u001b[34mval r2: 0.1676\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1676, mae 1.6499\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6499\u001b[0m\n",
      "\u001b[34mtest r2: 0.1676\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 92/200, training | loss 0.5443, r2 0.4554, mae 1.3251\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2064, mae 1.6354\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6354\u001b[0m\n",
      "\u001b[34mval r2: 0.2064\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2064, mae 1.6354\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6354\u001b[0m\n",
      "\u001b[34mtest r2: 0.2064\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 93/200, training | loss 0.5754, r2 0.4522, mae 1.3231\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2014, mae 1.6354\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6354\u001b[0m\n",
      "\u001b[34mval r2: 0.2014\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2014, mae 1.6354\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6354\u001b[0m\n",
      "\u001b[34mtest r2: 0.2014\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 94/200, training | loss 0.5259, r2 0.4981, mae 1.2632\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1470, mae 1.6991\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6991\u001b[0m\n",
      "\u001b[34mval r2: 0.1470\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1470, mae 1.6991\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6991\u001b[0m\n",
      "\u001b[34mtest r2: 0.1470\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 95/200, training | loss 0.5639, r2 0.4403, mae 1.3254\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1715, mae 1.6619\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6619\u001b[0m\n",
      "\u001b[34mval r2: 0.1715\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1715, mae 1.6619\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6619\u001b[0m\n",
      "\u001b[34mtest r2: 0.1715\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 96/200, training | loss 0.5359, r2 0.4617, mae 1.2983\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2181, mae 1.6168\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6168\u001b[0m\n",
      "\u001b[34mval r2: 0.2181\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2181, mae 1.6168\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6168\u001b[0m\n",
      "\u001b[34mtest r2: 0.2181\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 97/200, training | loss 0.5438, r2 0.4806, mae 1.3028\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2196, mae 1.5894\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5894\u001b[0m\n",
      "\u001b[34mval r2: 0.2196\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2196, mae 1.5894\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5894\u001b[0m\n",
      "\u001b[34mtest r2: 0.2196\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 98/200, training | loss 0.5522, r2 0.4677, mae 1.3330\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1873, mae 1.6198\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6198\u001b[0m\n",
      "\u001b[34mval r2: 0.1873\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1873, mae 1.6198\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6198\u001b[0m\n",
      "\u001b[34mtest r2: 0.1873\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 99/200, training | loss 0.5182, r2 0.4896, mae 1.2852\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1995, mae 1.5895\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5895\u001b[0m\n",
      "\u001b[34mval r2: 0.1995\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1995, mae 1.5895\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5895\u001b[0m\n",
      "\u001b[34mtest r2: 0.1995\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 100/200, training | loss 0.5466, r2 0.4615, mae 1.3030\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2627, mae 1.5210\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5210\u001b[0m\n",
      "\u001b[34mval r2: 0.2627\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2627, mae 1.5210\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5210\u001b[0m\n",
      "\u001b[34mtest r2: 0.2627\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 101/200, training | loss 0.5442, r2 0.4803, mae 1.2684\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2721, mae 1.5120\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5120\u001b[0m\n",
      "\u001b[34mval r2: 0.2721\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2721, mae 1.5120\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5120\u001b[0m\n",
      "\u001b[34mtest r2: 0.2721\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 102/200, training | loss 0.5479, r2 0.4970, mae 1.3059\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1969, mae 1.6504\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6504\u001b[0m\n",
      "\u001b[34mval r2: 0.1969\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1969, mae 1.6504\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6504\u001b[0m\n",
      "\u001b[34mtest r2: 0.1969\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 103/200, training | loss 0.5518, r2 0.4669, mae 1.3274\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2338, mae 1.5517\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5517\u001b[0m\n",
      "\u001b[34mval r2: 0.2338\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2338, mae 1.5517\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5517\u001b[0m\n",
      "\u001b[34mtest r2: 0.2338\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 104/200, training | loss 0.4497, r2 0.5608, mae 1.1821\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2503, mae 1.5766\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5766\u001b[0m\n",
      "\u001b[34mval r2: 0.2503\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2503, mae 1.5766\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5766\u001b[0m\n",
      "\u001b[34mtest r2: 0.2503\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 105/200, training | loss 0.4809, r2 0.5489, mae 1.1960\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2442, mae 1.5704\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5704\u001b[0m\n",
      "\u001b[34mval r2: 0.2442\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2442, mae 1.5704\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5704\u001b[0m\n",
      "\u001b[34mtest r2: 0.2442\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 106/200, training | loss 0.5203, r2 0.5032, mae 1.2802\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1794, mae 1.6722\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6722\u001b[0m\n",
      "\u001b[34mval r2: 0.1794\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1794, mae 1.6722\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6722\u001b[0m\n",
      "\u001b[34mtest r2: 0.1794\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 107/200, training | loss 0.5543, r2 0.4500, mae 1.3053\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2174, mae 1.5848\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5848\u001b[0m\n",
      "\u001b[34mval r2: 0.2174\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2174, mae 1.5848\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5848\u001b[0m\n",
      "\u001b[34mtest r2: 0.2174\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 108/200, training | loss 0.5151, r2 0.4844, mae 1.2862\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2454, mae 1.5652\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5652\u001b[0m\n",
      "\u001b[34mval r2: 0.2454\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2454, mae 1.5652\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5652\u001b[0m\n",
      "\u001b[34mtest r2: 0.2454\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 109/200, training | loss 0.5190, r2 0.4933, mae 1.2490\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2581, mae 1.5378\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5378\u001b[0m\n",
      "\u001b[34mval r2: 0.2581\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2581, mae 1.5378\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5378\u001b[0m\n",
      "\u001b[34mtest r2: 0.2581\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 110/200, training | loss 0.4983, r2 0.5236, mae 1.2224\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2237, mae 1.5844\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5844\u001b[0m\n",
      "\u001b[34mval r2: 0.2237\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2237, mae 1.5844\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5844\u001b[0m\n",
      "\u001b[34mtest r2: 0.2237\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 111/200, training | loss 0.4958, r2 0.5077, mae 1.2318\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2447, mae 1.5361\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5361\u001b[0m\n",
      "\u001b[34mval r2: 0.2447\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2447, mae 1.5361\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5361\u001b[0m\n",
      "\u001b[34mtest r2: 0.2447\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 112/200, training | loss 0.4451, r2 0.5614, mae 1.1963\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2633, mae 1.5297\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5297\u001b[0m\n",
      "\u001b[34mval r2: 0.2633\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2633, mae 1.5297\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5297\u001b[0m\n",
      "\u001b[34mtest r2: 0.2633\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 113/200, training | loss 0.4629, r2 0.5606, mae 1.1992\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2548, mae 1.5363\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5363\u001b[0m\n",
      "\u001b[34mval r2: 0.2548\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2548, mae 1.5363\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5363\u001b[0m\n",
      "\u001b[34mtest r2: 0.2548\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 114/200, training | loss 0.4644, r2 0.5459, mae 1.1881\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2339, mae 1.5776\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5776\u001b[0m\n",
      "\u001b[34mval r2: 0.2339\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2339, mae 1.5776\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5776\u001b[0m\n",
      "\u001b[34mtest r2: 0.2339\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 115/200, training | loss 0.4661, r2 0.5344, mae 1.1924\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2548, mae 1.5422\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5422\u001b[0m\n",
      "\u001b[34mval r2: 0.2548\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2548, mae 1.5422\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5422\u001b[0m\n",
      "\u001b[34mtest r2: 0.2548\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 116/200, training | loss 0.4130, r2 0.5896, mae 1.0956\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2592, mae 1.5613\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5613\u001b[0m\n",
      "\u001b[34mval r2: 0.2592\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2592, mae 1.5613\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5613\u001b[0m\n",
      "\u001b[34mtest r2: 0.2592\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 117/200, training | loss 0.4799, r2 0.5236, mae 1.1797\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2641, mae 1.5440\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5440\u001b[0m\n",
      "\u001b[34mval r2: 0.2641\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2641, mae 1.5440\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5440\u001b[0m\n",
      "\u001b[34mtest r2: 0.2641\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 118/200, training | loss 0.4737, r2 0.5381, mae 1.1745\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2140, mae 1.6962\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6962\u001b[0m\n",
      "\u001b[34mval r2: 0.2140\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2140, mae 1.6962\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6962\u001b[0m\n",
      "\u001b[34mtest r2: 0.2140\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 119/200, training | loss 0.4925, r2 0.5085, mae 1.2215\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2426, mae 1.5918\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5918\u001b[0m\n",
      "\u001b[34mval r2: 0.2426\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2426, mae 1.5918\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5918\u001b[0m\n",
      "\u001b[34mtest r2: 0.2426\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 120/200, training | loss 0.4494, r2 0.5612, mae 1.1788\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2037, mae 1.6544\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6544\u001b[0m\n",
      "\u001b[34mval r2: 0.2037\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2037, mae 1.6544\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6544\u001b[0m\n",
      "\u001b[34mtest r2: 0.2037\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 121/200, training | loss 0.4937, r2 0.5049, mae 1.2549\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2246, mae 1.6268\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6268\u001b[0m\n",
      "\u001b[34mval r2: 0.2246\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2246, mae 1.6268\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6268\u001b[0m\n",
      "\u001b[34mtest r2: 0.2246\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 122/200, training | loss 0.4597, r2 0.5410, mae 1.1737\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2114, mae 1.6411\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6411\u001b[0m\n",
      "\u001b[34mval r2: 0.2114\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2114, mae 1.6411\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6411\u001b[0m\n",
      "\u001b[34mtest r2: 0.2114\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 123/200, training | loss 0.4460, r2 0.5557, mae 1.1373\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2265, mae 1.6067\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6067\u001b[0m\n",
      "\u001b[34mval r2: 0.2265\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2265, mae 1.6067\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6067\u001b[0m\n",
      "\u001b[34mtest r2: 0.2265\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 124/200, training | loss 0.4350, r2 0.5651, mae 1.1315\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2359, mae 1.5815\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5815\u001b[0m\n",
      "\u001b[34mval r2: 0.2359\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2359, mae 1.5815\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5815\u001b[0m\n",
      "\u001b[34mtest r2: 0.2359\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 125/200, training | loss 0.4209, r2 0.5874, mae 1.1141\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1983, mae 1.6113\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6113\u001b[0m\n",
      "\u001b[34mval r2: 0.1983\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1983, mae 1.6113\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6113\u001b[0m\n",
      "\u001b[34mtest r2: 0.1983\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 126/200, training | loss 0.5000, r2 0.5090, mae 1.2405\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2484, mae 1.5537\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5537\u001b[0m\n",
      "\u001b[34mval r2: 0.2484\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2484, mae 1.5537\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5537\u001b[0m\n",
      "\u001b[34mtest r2: 0.2484\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 127/200, training | loss 0.4381, r2 0.5657, mae 1.1522\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2694, mae 1.5488\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5488\u001b[0m\n",
      "\u001b[34mval r2: 0.2694\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2694, mae 1.5488\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5488\u001b[0m\n",
      "\u001b[34mtest r2: 0.2694\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 128/200, training | loss 0.4399, r2 0.5720, mae 1.1648\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2580, mae 1.5744\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5744\u001b[0m\n",
      "\u001b[34mval r2: 0.2580\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2580, mae 1.5744\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5744\u001b[0m\n",
      "\u001b[34mtest r2: 0.2580\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 129/200, training | loss 0.4521, r2 0.5532, mae 1.2305\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2743, mae 1.5474\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5474\u001b[0m\n",
      "\u001b[34mval r2: 0.2743\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2743, mae 1.5474\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5474\u001b[0m\n",
      "\u001b[34mtest r2: 0.2743\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 130/200, training | loss 0.4135, r2 0.6001, mae 1.1248\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2544, mae 1.5639\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5639\u001b[0m\n",
      "\u001b[34mval r2: 0.2544\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2544, mae 1.5639\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5639\u001b[0m\n",
      "\u001b[34mtest r2: 0.2544\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 131/200, training | loss 0.3846, r2 0.6200, mae 1.0622\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2336, mae 1.5671\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5671\u001b[0m\n",
      "\u001b[34mval r2: 0.2336\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2336, mae 1.5671\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5671\u001b[0m\n",
      "\u001b[34mtest r2: 0.2336\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 132/200, training | loss 0.4308, r2 0.5759, mae 1.1494\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2327, mae 1.5874\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5874\u001b[0m\n",
      "\u001b[34mval r2: 0.2327\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2327, mae 1.5874\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5874\u001b[0m\n",
      "\u001b[34mtest r2: 0.2327\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 133/200, training | loss 0.4146, r2 0.5870, mae 1.1072\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2378, mae 1.6104\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6104\u001b[0m\n",
      "\u001b[34mval r2: 0.2378\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2378, mae 1.6104\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6104\u001b[0m\n",
      "\u001b[34mtest r2: 0.2378\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 134/200, training | loss 0.4225, r2 0.5850, mae 1.1242\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.1858, mae 1.7372\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7372\u001b[0m\n",
      "\u001b[34mval r2: 0.1858\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.1858, mae 1.7372\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7372\u001b[0m\n",
      "\u001b[34mtest r2: 0.1858\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 135/200, training | loss 0.4279, r2 0.5742, mae 1.1622\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2262, mae 1.6580\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6580\u001b[0m\n",
      "\u001b[34mval r2: 0.2262\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2262, mae 1.6580\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6580\u001b[0m\n",
      "\u001b[34mtest r2: 0.2262\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 136/200, training | loss 0.3865, r2 0.6154, mae 1.0859\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2462, mae 1.6631\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6631\u001b[0m\n",
      "\u001b[34mval r2: 0.2462\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2462, mae 1.6631\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6631\u001b[0m\n",
      "\u001b[34mtest r2: 0.2462\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 137/200, training | loss 0.4638, r2 0.5954, mae 1.2092\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2030, mae 1.6353\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6353\u001b[0m\n",
      "\u001b[34mval r2: 0.2030\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2030, mae 1.6353\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6353\u001b[0m\n",
      "\u001b[34mtest r2: 0.2030\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 138/200, training | loss 0.4506, r2 0.5519, mae 1.1851\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2029, mae 1.6399\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6399\u001b[0m\n",
      "\u001b[34mval r2: 0.2029\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2029, mae 1.6399\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6399\u001b[0m\n",
      "\u001b[34mtest r2: 0.2029\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 139/200, training | loss 0.3953, r2 0.6512, mae 1.1132\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2413, mae 1.5976\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5976\u001b[0m\n",
      "\u001b[34mval r2: 0.2413\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2413, mae 1.5976\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5976\u001b[0m\n",
      "\u001b[34mtest r2: 0.2413\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 140/200, training | loss 0.3995, r2 0.6000, mae 1.1084\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2819, mae 1.5311\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5311\u001b[0m\n",
      "\u001b[34mval r2: 0.2819\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2819, mae 1.5311\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5311\u001b[0m\n",
      "\u001b[34mtest r2: 0.2819\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 141/200, training | loss 0.4171, r2 0.5930, mae 1.1167\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2914, mae 1.5207\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5207\u001b[0m\n",
      "\u001b[34mval r2: 0.2914\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2914, mae 1.5207\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5207\u001b[0m\n",
      "\u001b[34mtest r2: 0.2914\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  141\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  141\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 142/200, training | loss 0.4469, r2 0.5544, mae 1.1723\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2950, mae 1.5141\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5141\u001b[0m\n",
      "\u001b[34mval r2: 0.2950\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2950, mae 1.5141\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5141\u001b[0m\n",
      "\u001b[34mtest r2: 0.2950\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  142\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  142\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 143/200, training | loss 0.4077, r2 0.5929, mae 1.0731\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2743, mae 1.5349\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5349\u001b[0m\n",
      "\u001b[34mval r2: 0.2743\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2743, mae 1.5349\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5349\u001b[0m\n",
      "\u001b[34mtest r2: 0.2743\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 144/200, training | loss 0.3692, r2 0.6305, mae 1.0609\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2638, mae 1.5411\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5411\u001b[0m\n",
      "\u001b[34mval r2: 0.2638\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2638, mae 1.5411\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5411\u001b[0m\n",
      "\u001b[34mtest r2: 0.2638\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 145/200, training | loss 0.3673, r2 0.6342, mae 1.0270\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2660, mae 1.5401\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5401\u001b[0m\n",
      "\u001b[34mval r2: 0.2660\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2660, mae 1.5401\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5401\u001b[0m\n",
      "\u001b[34mtest r2: 0.2660\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 146/200, training | loss 0.3758, r2 0.6312, mae 1.0627\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2611, mae 1.5503\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5503\u001b[0m\n",
      "\u001b[34mval r2: 0.2611\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2611, mae 1.5503\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5503\u001b[0m\n",
      "\u001b[34mtest r2: 0.2611\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 147/200, training | loss 0.3610, r2 0.6436, mae 1.0828\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2614, mae 1.5572\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5572\u001b[0m\n",
      "\u001b[34mval r2: 0.2614\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2614, mae 1.5572\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5572\u001b[0m\n",
      "\u001b[34mtest r2: 0.2614\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 148/200, training | loss 0.3691, r2 0.6316, mae 1.0730\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2738, mae 1.5381\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5381\u001b[0m\n",
      "\u001b[34mval r2: 0.2738\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2738, mae 1.5381\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5381\u001b[0m\n",
      "\u001b[34mtest r2: 0.2738\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 149/200, training | loss 0.3637, r2 0.6361, mae 1.0570\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2843, mae 1.5268\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5268\u001b[0m\n",
      "\u001b[34mval r2: 0.2843\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2843, mae 1.5268\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5268\u001b[0m\n",
      "\u001b[34mtest r2: 0.2843\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 150/200, training | loss 0.3580, r2 0.6415, mae 1.0186\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2820, mae 1.5383\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5383\u001b[0m\n",
      "\u001b[34mval r2: 0.2820\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2820, mae 1.5383\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5383\u001b[0m\n",
      "\u001b[34mtest r2: 0.2820\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 151/200, training | loss 0.3763, r2 0.6247, mae 1.0549\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2898, mae 1.5506\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5506\u001b[0m\n",
      "\u001b[34mval r2: 0.2898\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2898, mae 1.5506\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5506\u001b[0m\n",
      "\u001b[34mtest r2: 0.2898\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 152/200, training | loss 0.3803, r2 0.6248, mae 1.0629\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3106, mae 1.5207\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5207\u001b[0m\n",
      "\u001b[34mval r2: 0.3106\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3106, mae 1.5207\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5207\u001b[0m\n",
      "\u001b[34mtest r2: 0.3106\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  152\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  152\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 153/200, training | loss 0.3356, r2 0.6742, mae 0.9836\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2951, mae 1.5598\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5598\u001b[0m\n",
      "\u001b[34mval r2: 0.2951\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2951, mae 1.5598\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5598\u001b[0m\n",
      "\u001b[34mtest r2: 0.2951\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 154/200, training | loss 0.3857, r2 0.6159, mae 1.0646\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2976, mae 1.5526\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5526\u001b[0m\n",
      "\u001b[34mval r2: 0.2976\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2976, mae 1.5526\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5526\u001b[0m\n",
      "\u001b[34mtest r2: 0.2976\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 155/200, training | loss 0.3536, r2 0.6500, mae 0.9986\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2842, mae 1.5539\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5539\u001b[0m\n",
      "\u001b[34mval r2: 0.2842\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2842, mae 1.5539\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5539\u001b[0m\n",
      "\u001b[34mtest r2: 0.2842\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 156/200, training | loss 0.3648, r2 0.6344, mae 1.0272\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2562, mae 1.5803\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5803\u001b[0m\n",
      "\u001b[34mval r2: 0.2562\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2562, mae 1.5803\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5803\u001b[0m\n",
      "\u001b[34mtest r2: 0.2562\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 157/200, training | loss 0.3658, r2 0.6357, mae 1.0638\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2577, mae 1.5771\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5771\u001b[0m\n",
      "\u001b[34mval r2: 0.2577\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2577, mae 1.5771\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5771\u001b[0m\n",
      "\u001b[34mtest r2: 0.2577\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 158/200, training | loss 0.3607, r2 0.6402, mae 1.0176\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2660, mae 1.5621\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5621\u001b[0m\n",
      "\u001b[34mval r2: 0.2660\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2660, mae 1.5621\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5621\u001b[0m\n",
      "\u001b[34mtest r2: 0.2660\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 159/200, training | loss 0.3568, r2 0.6440, mae 1.0389\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2749, mae 1.5426\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5426\u001b[0m\n",
      "\u001b[34mval r2: 0.2749\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2749, mae 1.5426\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5426\u001b[0m\n",
      "\u001b[34mtest r2: 0.2749\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 160/200, training | loss 0.3546, r2 0.6640, mae 1.0482\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2771, mae 1.5634\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5634\u001b[0m\n",
      "\u001b[34mval r2: 0.2771\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2771, mae 1.5634\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5634\u001b[0m\n",
      "\u001b[34mtest r2: 0.2771\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 161/200, training | loss 0.3269, r2 0.6719, mae 0.9926\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2857, mae 1.5478\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5478\u001b[0m\n",
      "\u001b[34mval r2: 0.2857\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2857, mae 1.5478\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5478\u001b[0m\n",
      "\u001b[34mtest r2: 0.2857\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 162/200, training | loss 0.3565, r2 0.6460, mae 1.0273\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2895, mae 1.5453\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5453\u001b[0m\n",
      "\u001b[34mval r2: 0.2895\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2895, mae 1.5453\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5453\u001b[0m\n",
      "\u001b[34mtest r2: 0.2895\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 163/200, training | loss 0.3950, r2 0.6066, mae 1.0804\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2983, mae 1.5411\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5411\u001b[0m\n",
      "\u001b[34mval r2: 0.2983\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2983, mae 1.5411\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5411\u001b[0m\n",
      "\u001b[34mtest r2: 0.2983\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 164/200, training | loss 0.3289, r2 0.6705, mae 1.0139\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3084, mae 1.5037\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5037\u001b[0m\n",
      "\u001b[34mval r2: 0.3084\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3084, mae 1.5037\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5037\u001b[0m\n",
      "\u001b[34mtest r2: 0.3084\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 165/200, training | loss 0.3505, r2 0.6726, mae 1.0409\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2699, mae 1.6362\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6362\u001b[0m\n",
      "\u001b[34mval r2: 0.2699\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2699, mae 1.6362\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6362\u001b[0m\n",
      "\u001b[34mtest r2: 0.2699\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 166/200, training | loss 0.3936, r2 0.6225, mae 1.0698\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2946, mae 1.5646\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5646\u001b[0m\n",
      "\u001b[34mval r2: 0.2946\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2946, mae 1.5646\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5646\u001b[0m\n",
      "\u001b[34mtest r2: 0.2946\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 167/200, training | loss 0.4214, r2 0.6509, mae 1.1263\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2497, mae 1.5873\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5873\u001b[0m\n",
      "\u001b[34mval r2: 0.2497\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2497, mae 1.5873\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5873\u001b[0m\n",
      "\u001b[34mtest r2: 0.2497\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 168/200, training | loss 0.3629, r2 0.6361, mae 1.0467\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2413, mae 1.7017\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7017\u001b[0m\n",
      "\u001b[34mval r2: 0.2413\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2413, mae 1.7017\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7017\u001b[0m\n",
      "\u001b[34mtest r2: 0.2413\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 169/200, training | loss 0.4171, r2 0.6366, mae 1.1520\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2793, mae 1.5092\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5092\u001b[0m\n",
      "\u001b[34mval r2: 0.2793\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2793, mae 1.5092\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5092\u001b[0m\n",
      "\u001b[34mtest r2: 0.2793\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 170/200, training | loss 0.3497, r2 0.6600, mae 1.0356\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2811, mae 1.5429\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5429\u001b[0m\n",
      "\u001b[34mval r2: 0.2811\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2811, mae 1.5429\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5429\u001b[0m\n",
      "\u001b[34mtest r2: 0.2811\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 171/200, training | loss 0.4213, r2 0.6325, mae 1.1270\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2675, mae 1.5239\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5239\u001b[0m\n",
      "\u001b[34mval r2: 0.2675\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2675, mae 1.5239\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5239\u001b[0m\n",
      "\u001b[34mtest r2: 0.2675\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 172/200, training | loss 0.3473, r2 0.6559, mae 1.0231\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2609, mae 1.5950\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5950\u001b[0m\n",
      "\u001b[34mval r2: 0.2609\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2609, mae 1.5950\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5950\u001b[0m\n",
      "\u001b[34mtest r2: 0.2609\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 173/200, training | loss 0.3909, r2 0.6274, mae 1.0716\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2813, mae 1.5232\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5232\u001b[0m\n",
      "\u001b[34mval r2: 0.2813\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2813, mae 1.5232\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5232\u001b[0m\n",
      "\u001b[34mtest r2: 0.2813\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 174/200, training | loss 0.3610, r2 0.6456, mae 1.0245\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2960, mae 1.5163\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5163\u001b[0m\n",
      "\u001b[34mval r2: 0.2960\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2960, mae 1.5163\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5163\u001b[0m\n",
      "\u001b[34mtest r2: 0.2960\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 175/200, training | loss 0.3666, r2 0.6469, mae 1.0221\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3108, mae 1.4736\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.4736\u001b[0m\n",
      "\u001b[34mval r2: 0.3108\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3108, mae 1.4736\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.4736\u001b[0m\n",
      "\u001b[34mtest r2: 0.3108\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  175\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  175\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 176/200, training | loss 0.3036, r2 0.7069, mae 0.9320\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2769, mae 1.6291\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6291\u001b[0m\n",
      "\u001b[34mval r2: 0.2769\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2769, mae 1.6291\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6291\u001b[0m\n",
      "\u001b[34mtest r2: 0.2769\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 177/200, training | loss 0.3692, r2 0.6526, mae 1.0550\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2896, mae 1.5688\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5688\u001b[0m\n",
      "\u001b[34mval r2: 0.2896\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2896, mae 1.5688\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5688\u001b[0m\n",
      "\u001b[34mtest r2: 0.2896\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 178/200, training | loss 0.3733, r2 0.6263, mae 1.0420\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3313, mae 1.4909\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.4909\u001b[0m\n",
      "\u001b[34mval r2: 0.3313\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3313, mae 1.4909\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.4909\u001b[0m\n",
      "\u001b[34mtest r2: 0.3313\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  178\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  178\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 179/200, training | loss 0.4091, r2 0.6268, mae 1.0825\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3085, mae 1.5141\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5141\u001b[0m\n",
      "\u001b[34mval r2: 0.3085\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3085, mae 1.5141\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5141\u001b[0m\n",
      "\u001b[34mtest r2: 0.3085\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 180/200, training | loss 0.3608, r2 0.6662, mae 1.0619\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2450, mae 1.7618\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7618\u001b[0m\n",
      "\u001b[34mval r2: 0.2450\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2450, mae 1.7618\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7618\u001b[0m\n",
      "\u001b[34mtest r2: 0.2450\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 181/200, training | loss 0.4029, r2 0.6431, mae 1.1168\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2413, mae 1.6758\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6758\u001b[0m\n",
      "\u001b[34mval r2: 0.2413\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2413, mae 1.6758\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6758\u001b[0m\n",
      "\u001b[34mtest r2: 0.2413\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 182/200, training | loss 0.3415, r2 0.7012, mae 1.0274\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2723, mae 1.5670\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5670\u001b[0m\n",
      "\u001b[34mval r2: 0.2723\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2723, mae 1.5670\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5670\u001b[0m\n",
      "\u001b[34mtest r2: 0.2723\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 183/200, training | loss 0.3118, r2 0.7104, mae 0.9942\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2833, mae 1.5659\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5659\u001b[0m\n",
      "\u001b[34mval r2: 0.2833\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2833, mae 1.5659\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5659\u001b[0m\n",
      "\u001b[34mtest r2: 0.2833\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 184/200, training | loss 0.3650, r2 0.6844, mae 1.0236\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2583, mae 1.5492\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5492\u001b[0m\n",
      "\u001b[34mval r2: 0.2583\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2583, mae 1.5492\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5492\u001b[0m\n",
      "\u001b[34mtest r2: 0.2583\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 185/200, training | loss 0.3358, r2 0.6666, mae 1.0106\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2245, mae 1.7446\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7446\u001b[0m\n",
      "\u001b[34mval r2: 0.2245\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2245, mae 1.7446\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7446\u001b[0m\n",
      "\u001b[34mtest r2: 0.2245\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 186/200, training | loss 0.4353, r2 0.6151, mae 1.1540\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2847, mae 1.5040\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5040\u001b[0m\n",
      "\u001b[34mval r2: 0.2847\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2847, mae 1.5040\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5040\u001b[0m\n",
      "\u001b[34mtest r2: 0.2847\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 187/200, training | loss 0.3298, r2 0.6899, mae 0.9905\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2739, mae 1.5284\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5284\u001b[0m\n",
      "\u001b[34mval r2: 0.2739\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2739, mae 1.5284\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5284\u001b[0m\n",
      "\u001b[34mtest r2: 0.2739\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 188/200, training | loss 0.3667, r2 0.6651, mae 1.0463\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2882, mae 1.5030\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5030\u001b[0m\n",
      "\u001b[34mval r2: 0.2882\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2882, mae 1.5030\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5030\u001b[0m\n",
      "\u001b[34mtest r2: 0.2882\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 189/200, training | loss 0.3984, r2 0.6138, mae 1.1034\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3064, mae 1.4974\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.4974\u001b[0m\n",
      "\u001b[34mval r2: 0.3064\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3064, mae 1.4974\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.4974\u001b[0m\n",
      "\u001b[34mtest r2: 0.3064\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 190/200, training | loss 0.3263, r2 0.6908, mae 0.9860\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2723, mae 1.6521\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6521\u001b[0m\n",
      "\u001b[34mval r2: 0.2723\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2723, mae 1.6521\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6521\u001b[0m\n",
      "\u001b[34mtest r2: 0.2723\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 191/200, training | loss 0.3708, r2 0.6373, mae 1.0740\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2995, mae 1.5451\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5451\u001b[0m\n",
      "\u001b[34mval r2: 0.2995\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2995, mae 1.5451\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5451\u001b[0m\n",
      "\u001b[34mtest r2: 0.2995\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 192/200, training | loss 0.3457, r2 0.6534, mae 1.0081\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3338, mae 1.5058\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5058\u001b[0m\n",
      "\u001b[34mval r2: 0.3338\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3338, mae 1.5058\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5058\u001b[0m\n",
      "\u001b[34mtest r2: 0.3338\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mBest val epoch:  192\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mBest test epoch:  192\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mepoch 193/200, training | loss 0.4358, r2 0.6802, mae 1.1671\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3059, mae 1.5030\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5030\u001b[0m\n",
      "\u001b[34mval r2: 0.3059\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3059, mae 1.5030\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5030\u001b[0m\n",
      "\u001b[34mtest r2: 0.3059\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 194/200, training | loss 0.3335, r2 0.6719, mae 1.0017\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2489, mae 1.7203\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.7203\u001b[0m\n",
      "\u001b[34mval r2: 0.2489\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2489, mae 1.7203\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.7203\u001b[0m\n",
      "\u001b[34mtest r2: 0.2489\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 195/200, training | loss 0.3967, r2 0.6652, mae 1.1314\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2555, mae 1.6676\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6676\u001b[0m\n",
      "\u001b[34mval r2: 0.2555\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2555, mae 1.6676\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6676\u001b[0m\n",
      "\u001b[34mtest r2: 0.2555\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 196/200, training | loss 0.3625, r2 0.6704, mae 1.0386\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2884, mae 1.5152\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5152\u001b[0m\n",
      "\u001b[34mval r2: 0.2884\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2884, mae 1.5152\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5152\u001b[0m\n",
      "\u001b[34mtest r2: 0.2884\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 197/200, training | loss 0.3315, r2 0.6798, mae 0.9894\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3045, mae 1.5103\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5103\u001b[0m\n",
      "\u001b[34mval r2: 0.3045\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3045, mae 1.5103\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5103\u001b[0m\n",
      "\u001b[34mtest r2: 0.3045\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 198/200, training | loss 0.3661, r2 0.6861, mae 1.0622\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.3096, mae 1.4806\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.4806\u001b[0m\n",
      "\u001b[34mval r2: 0.3096\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.3096, mae 1.4806\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.4806\u001b[0m\n",
      "\u001b[34mtest r2: 0.3096\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 199/200, training | loss 0.2998, r2 0.7128, mae 0.9207\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2927, mae 1.5889\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.5889\u001b[0m\n",
      "\u001b[34mval r2: 0.2927\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2927, mae 1.5889\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.5889\u001b[0m\n",
      "\u001b[34mtest r2: 0.2927\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mepoch 200/200, training | loss 0.3287, r2 0.6806, mae 1.0137\u001b[0m\n",
      "\u001b[34mvalidation results, r2 0.2794, mae 1.6855\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mval mae: 1.6855\u001b[0m\n",
      "\u001b[34mval r2: 0.2794\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest results, r2 0.2794, mae 1.6855\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mtest mae: 1.6855\u001b[0m\n",
      "\u001b[34mtest r2: 0.2794\u001b[0m\n",
      "\u001b[34m------\u001b[0m\n",
      "\u001b[34mSaving the model\u001b[0m\n",
      "\u001b[34mUsing backend: pytorch\u001b[0m\n",
      "\u001b[34m2022-12-16 03:37:50,294 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-12-16 03:38:06 Uploading - Uploading generated training model\n",
      "2022-12-16 03:38:06 Completed - Training job completed\n",
      "Training seconds: 705\n",
      "Billable seconds: 705\n"
     ]
    }
   ],
   "source": [
    "# Launch SageMaker training job\n",
    "estimator.fit({'train': s3_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f7945e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-03-24-01-215/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {estimator.output_path}{estimator.latest_training_job.job_name}/output/model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5536c",
   "metadata": {},
   "source": [
    "## Go to the next notebook : 3 local inference potentialnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1ca92",
   "metadata": {},
   "source": [
    "### (Optional) ファインチューニングジョブを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "estimator_ft = PyTorch(\n",
    "    entry_point=\"main.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    hyperparameters={\n",
    "        \"lr\":0.001,\n",
    "        \"fine_tune\":True,\n",
    "        \"pretrained_model\":'<your S3 prefix of a trained model>/model.tar.gz'\n",
    "    },\n",
    "    metric_definitions=metric_definitions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch SageMaker training job\n",
    "estimator_ft.fit({'train': s3_input_ft})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf47b6",
   "metadata": {},
   "source": [
    "### (Optional) ハイパーパラメータチューニングジョブを実行\n",
    "\n",
    "SageMakerは、ハイパーパラメータの組み合わせを変えて複数の学習ジョブを開始し、最も優れたモデル性能を持つセットを見つけるHyperparameter Tuningを提供します。チューニングするハイパーパラメータとその値を指定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8144cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.01),\n",
    "    \"num_epochs\": IntegerParameter(100, 200),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141985d5",
   "metadata": {},
   "source": [
    "次に、チューニングしたい目的メトリクスとその定義を指定します。これには、SageMaker Training JobのAmazon CloudWatch Logsからそのメトリックを抽出するために必要な正規表現（regex）が含まれます。この例では、\"mae \"と \"r2 \"がサポートされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"mae\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c1b37c",
   "metadata": {},
   "source": [
    "\n",
    "ここで、HyperparameterTunerオブジェクトを作成し、以下の変数を渡します。\n",
    "\n",
    " * 上記で作成した学習推定量\n",
    " * ハイパーパラメータの範囲\n",
    " * 目的メトリクスの名前と定義\n",
    " * 合計で実行するトレーニングジョブの数と、同時に実行するトレーニングジョブの数。並列ジョブを増やすとチューニングが早く終わりますが、精度が犠牲になる場合があります。並列ジョブの値をトレーニングジョブの総数の10%以下に設定することをお勧めします(この例では短くするために高く設定します)。\n",
    " * 目的指標を最大化するか、最小化するか。デフォルトでは「最大化」になっているため、ここでは指定していません。\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_tags = [{\"Key\": \"ML Task\", \"Value\": \"DGL-Lifesci\"}]\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    tags=task_tags,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c409b",
   "metadata": {},
   "source": [
    "最後に、`.fit().`メソッドを呼び出してチューニングジョブを実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcee0b8",
   "metadata": {},
   "source": [
    "Hyperparameter Tuningのジョブが正常に開始され、InProgressになっていることを確認するために、ジョブの状態を簡単にチェックしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "sagemaker_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)[\"HyperParameterTuningJobStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100a6fd",
   "metadata": {},
   "source": [
    "### Output\n",
    "ハイパーパラメータのチューニングが終了すると、以下のように最適なモデルが得られます。SageMakerのハイパーパラメータチューニングジョブにより、計算量の多い学習ジョブを簡単に管理し、最適なモデル構成を見つけることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b99edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "tuner_status = sagemaker_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "if tuner_status == \"Completed\":\n",
    "    best_training_job_summary = sagemaker_boto_client.describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)[\"BestTrainingJob\"]\n",
    "    best_training_job_details = sagemaker_boto_client.describe_training_job(\n",
    "        TrainingJobName=best_training_job_summary[\"TrainingJobName\"])\n",
    "\n",
    "    trained_model_s3_uri = best_training_job_details[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "    s3_client.download_file(trained_model_s3_uri.split('/')[2], ('/').join(trained_model_s3_uri.split('/')[3:]), \"model.tar.gz\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
