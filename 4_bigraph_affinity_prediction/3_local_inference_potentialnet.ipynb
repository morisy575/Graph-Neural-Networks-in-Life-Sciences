{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1256ea85",
   "metadata": {},
   "source": [
    "# PotentialNet モデルをダウンロード、ローカルでホスティング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c92339",
   "metadata": {},
   "source": [
    "このノートブックでは、SageMakerで学習させたPotentialNet Modelの使い方を紹介します。\n",
    "まず、SageMaker Training Jobで作成された`model.tar.gz`ファイルをこのディレクトリにダウンロードしてください。そして、モデルファイルを以下のコマンドで解凍してください。すると、`best_test_model.pth`, `best_val_model.pth`, `model.pth`の3つのファイルが表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee828ea2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_val_model.pth\n",
      "best_test_model.pth\n",
      "model.pth\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad24c0",
   "metadata": {},
   "source": [
    "`data_dir`をセットしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6796fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'graph_files_v2020_core_13_withPDBID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f2852",
   "metadata": {},
   "source": [
    "次に、SageMaker Training Jobで行ったように、Custom Dataset / DataLoader オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c0fbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.append('code/')\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, lst_graph1_paths):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.len = len(lst_graph1_paths)\n",
    "        self.lst = lst_graph1_paths\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        graphs1, label_dict = load_graphs(self.lst[index])\n",
    "        graphs2, label_dict = load_graphs(self.lst[index].replace('_g1.bin', '_g2.bin'))\n",
    "        label = label_dict['glabel']\n",
    "        \n",
    "        graphs1_batch = [dgl.batch([graphs1[i],graphs1[i+1]]) for i in range(0, int(len(graphs1)), 2)]\n",
    "        bg = [tuple([graphs1_batch[i],graphs2[i]]) for i in range(0, int(len(graphs2)), 1)]\n",
    "        \n",
    "        return bg[0], label\n",
    "    \n",
    "def collate(data):\n",
    "    graphs, labels = map(list, zip(*data))\n",
    "    if (type(graphs[0]) == tuple):\n",
    "        bg1 = dgl.batch([g[0] for g in graphs])\n",
    "        bg2 = dgl.batch([g[1] for g in graphs])\n",
    "        bg = (bg1, bg2) # return a tuple for PotentialNet\n",
    "    else:\n",
    "        bg = dgl.batch(graphs)\n",
    "        for nty in bg.ntypes:\n",
    "            bg.set_n_initializer(dgl.init.zero_initializer, ntype=nty)\n",
    "        for ety in bg.canonical_etypes:\n",
    "            bg.set_e_initializer(dgl.init.zero_initializer, etype=ety)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    return bg, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a453424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from dgl.data.utils import load_graphs\n",
    "import dgl\n",
    "\n",
    "lst_g1 = glob.glob(data_dir +\"/\"+ \"**_g1.bin\")\n",
    "inf_data_set = MyDataset(lst_g1)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "        dataset=inf_data_set,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate,\n",
    "        pin_memory=True,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d7ff0",
   "metadata": {},
   "source": [
    "同じ構成のPotentialNetモデルを再作成し、学習済みモデルの重みをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29b43cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dgllife.model import ACNN, PotentialNet\n",
    "from configure import get_exp_configure\n",
    "from utils import load_dataset, load_model, rand_hyperparams, set_random_seed\n",
    "import torch\n",
    "\n",
    "args = {}\n",
    "args[\"model\"] = \"PotentialNet\"\n",
    "args[\"dataset_option\"] = \"PDBBind_refined_pocket_scaffold\"\n",
    "args[\"exp\"] = \"_\".join([args[\"model\"], args[\"dataset_option\"]])\n",
    "\n",
    "default_exp = get_exp_configure(args[\"exp\"])\n",
    "for i in default_exp.keys():\n",
    "    args.setdefault(i, default_exp[i])\n",
    "args['distance_bins'] =  [1.5, 2.5, 2.7, 2.9, 3.1, 3.3, 3.5, 4.5]\n",
    "\n",
    "model = PotentialNet(n_etypes=(len(args['distance_bins'])+ 5),\n",
    "                             f_in=args['f_in'],\n",
    "                             f_bond=args['f_bond'],\n",
    "                             f_spatial=args['f_spatial'],\n",
    "                             f_gather=args['f_gather'],\n",
    "                             n_rows_fc=args['n_rows_fc'],\n",
    "                             n_bond_conv_steps=args['n_bond_conv_steps'],\n",
    "                             n_spatial_conv_steps=args['n_spatial_conv_steps'],\n",
    "                             dropouts=args['dropouts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797305de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PotentialNet(\n",
       "  (stage_1_model): CustomizedGatedGraphConv(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (1): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (2): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (3): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (4): Linear(in_features=48, out_features=48, bias=True)\n",
       "    )\n",
       "    (gru): GRUCell(48, 48)\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "    (i_nn): Linear(in_features=92, out_features=48, bias=True)\n",
       "    (j_nn): Linear(in_features=48, out_features=48, bias=True)\n",
       "  )\n",
       "  (stage_2_model): CustomizedGatedGraphConv(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (1): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (2): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (3): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (4): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (5): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (6): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (7): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (8): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (9): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (10): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (11): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (12): Linear(in_features=48, out_features=48, bias=True)\n",
       "    )\n",
       "    (gru): GRUCell(48, 48)\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "    (i_nn): Linear(in_features=96, out_features=48, bias=True)\n",
       "    (j_nn): Linear(in_features=48, out_features=48, bias=True)\n",
       "  )\n",
       "  (stage_3_model): StagedFCNN(\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=48, out_features=48, bias=True)\n",
       "      (1): Linear(in_features=48, out_features=24, bias=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=24, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_test_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d202ac4",
   "metadata": {},
   "source": [
    "最後に、テストデータを用いて予測を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a837e85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-16 03:40:56.293 pytorch-1-6-cpu-py36-u-ml-m5-large-b31d7ee5bb77b3d378e3f873d2c8:587 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-12-16 03:40:56.407 pytorch-1-6-cpu-py36-u-ml-m5-large-b31d7ee5bb77b3d378e3f873d2c8:587 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "tensor([[-0.5316]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2589]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4094]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4931]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1898]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6494]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1141]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7074]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.7248]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9280]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.5679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0930]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.7588]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7639]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1030]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0028]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1452]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3331]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4830]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0676]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3940]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2536]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8273]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9643]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7042]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.6437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.1272]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.6117]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1437]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.3358]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3150]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.7901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9976]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1244]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4852]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.2010]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1526]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.9148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2304]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.9461]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2296]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0045]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6864]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7880]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2898]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1422]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2.1179]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0749]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6112]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0127]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0180]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2686]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6172]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4383]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.6443]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2409]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1290]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2687]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0091]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7124]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1350]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2.0829]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2962]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2.0875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4901]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7341]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2326]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1067]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7281]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5473]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2194]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4505]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0961]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4343]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5669]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4925]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3749]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0607]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1207]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2002]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6505]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8316]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7679]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5781]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.4119]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1096]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4613]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2272]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4924]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3806]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.2391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5566]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1128]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.2761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0242]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2440]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.1593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0693]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0374]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1402]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1717]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3151]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.4305]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4740]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4521]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.4379]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7518]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.6859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0872]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0981]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1058]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1692]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1615]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9963]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4726]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.3410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0962]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1131]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2287]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5742]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0555]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7206]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7023]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2816]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3458]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.4148]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2779]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.1708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8859]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.8651]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1890]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3147]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4633]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4360]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6649]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.3605]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.3402]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1059]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8612]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1510]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9711]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5130]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6106]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5038]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3769]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2379]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.5456]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2.3928]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0204]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0185]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5596]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2893]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.5843]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3785]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1583]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for batch_id, batch_data in enumerate(data_loader):\n",
    "        bg, labels = batch_data\n",
    "        labels = labels\n",
    "        bigraph_canonical, knn_graph = bg  # unpack stage1_graph, stage2_graph\n",
    "        bigraph_canonical = bigraph_canonical\n",
    "        knn_graph = knn_graph\n",
    "        prediction = model(bigraph_canonical, knn_graph)\n",
    "        print(prediction)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
