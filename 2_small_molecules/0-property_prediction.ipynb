{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01155ce",
   "metadata": {},
   "source": [
    "# DGL-LifeSciによる分子特性予測\n",
    "\n",
    "DGL-LifeSciは、グラフニューラルネットワーク（GNN）をライフサイエンスの様々な問題に適用するためのDGLベースのパッケージです。本デモでは、分子特性予測のためのGNNを開発します。\n",
    "\n",
    "インストール方法については、 [[Github repo]](https://github.com/awslabs/dgl-lifesci)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088bfe42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install dgl\n",
    "!pip install dgllife\n",
    "!conda install -c rdkit -y rdkit==2018.09.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f86b7",
   "metadata": {},
   "source": [
    "## Section 1: グラフの構築\n",
    "\n",
    "GNNを分子に適用するための最初のステップは、分子をグラフに変換することです。最も直感的には、ノードが原子(atom)、エッジが原子間の結合(bond)に対応する分子グラフを構築することになります。以下のコードでは、SMILES（simplified molecular-input line-entry system）文字列からRDKitを用いて分子グラフをプロットしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "IPythonConsole.ipython_useSVG = True\n",
    "smiles = 'c1ncncc1C(=O)[O-]'\n",
    "mol = Chem.MolFromSmiles('c1ncncc1C(=O)[O-]')\n",
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ef95a",
   "metadata": {},
   "source": [
    "DGL-LifeSciは、RDKitの分子オブジェクトを、対応する分子グラフを表すDGLGraphに変換するための `MolToBigraph`モジュールを提供します。ノードの数は原子の数と同じです。グラフは双方向性であり、$(i, j)$と$(j, i)$は異なる辺であることを意味するので、辺の数は結合の数の2倍になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import MolToBigraph\n",
    "\n",
    "mol_to_g = MolToBigraph()\n",
    "g = mol_to_g(mol)\n",
    "print(g)\n",
    "assert g.num_nodes() == mol.GetNumAtoms()\n",
    "assert g.num_edges() == 2 * mol.GetNumBonds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe2b63",
   "metadata": {},
   "source": [
    "特に原子の3次元座標が利用可能な場合、半径グラフ(radius graph)やKNN（k近傍）グラフなどがよく利用されています。DGL-LifeSciのグラフ構築法の一覧は、https://lifesci.dgl.ai/api/utils.mols.html#graph-construction を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf88ee",
   "metadata": {},
   "source": [
    "## Section 2: 特徴量化(Featurization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ce9d5",
   "metadata": {},
   "source": [
    "GNNがうまく機能するためには、構造情報と特徴情報の両方が必要です。従って、グラフの入力ノードやエッジの特徴を準備することは重要なステップです。\n",
    "\n",
    "分子グラフの場合、ノードの特徴として原子タイプ/原子番号、結合の特徴として結合の種類などの情報を考慮するのが一般的です。Atom Featurizerの例を以下に示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def atom_mass(atom):\n",
    "    \"\"\"\n",
    "    atom: RDKit atom instance\n",
    "    \"\"\"\n",
    "    return [atom.GetMass() * 0.01]\n",
    "\n",
    "atom = mol.GetAtomWithIdx(0)\n",
    "print(atom_mass(atom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f9ba61",
   "metadata": {},
   "source": [
    "DGL-LifeSciは原子と結合に関するfeatureizerをビルトインしており、その一覧はhttps://lifesci.dgl.ai/api/utils.mols.html#featurization-for-nodes で参照できます。\n",
    "また、複数のfeatureizerを組み合わせることもよくありますが、その場合は `ConcatFeaturizer` が役に立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import ConcatFeaturizer, atom_formal_charge\n",
    "\n",
    "\n",
    "atom_featurizer = ConcatFeaturizer([atom_mass, atom_formal_charge])\n",
    "print(atom_featurizer(atom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1c5fe",
   "metadata": {},
   "source": [
    "DGL-LifeSciは、分子内のすべての原子に特徴量化を適用するための`BaseAtomFeaturizer`モジュールと、分子内のすべての結合に特徴づけを適用するための`BaseBondFeaturizer`モジュールを提供しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import BaseAtomFeaturizer\n",
    "\n",
    "mol_atom_featurizer = BaseAtomFeaturizer({'feat': atom_featurizer})\n",
    "print('feat size:', mol_atom_featurizer.feat_size())\n",
    "print(mol_atom_featurizer(mol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122217d",
   "metadata": {},
   "source": [
    "## Section 3: データセットの準備\n",
    "\n",
    "DGL-LifeSciでは、データセットのロードに広く使われているCSV（Comma-Sparated Values）形式を採用しています。デモでは、まずCSV形式のデータファイルをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195918c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import download, _get_dgl_url, extract_archive\n",
    "\n",
    "url = 'dataset/FreeSolv.zip'\n",
    "data_path = 'FreeSolv.zip'\n",
    "download(_get_dgl_url(url), path=data_path)\n",
    "extract_archive(data_path, './FreeSolv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f813b7b",
   "metadata": {},
   "source": [
    "CSVファイルには、SMILES文字列の列（下記ファイルではsmiles）と、プロパティの列（下記ファイルではexptとcalc）が1つまたは複数あることが必要です。ここでexptとは実験値、calcとは計算値を表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5302b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('FreeSolv/SAMPL.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4762a8f",
   "metadata": {},
   "source": [
    "DGL-LifeSciでは、CSVデータファイルをロードし、グラフの構築と特徴量化を行うための `MoleculeCSVDataset`を提供しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12174509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.data import MoleculeCSVDataset\n",
    "from dgllife.utils import AttentiveFPAtomFeaturizer, AttentiveFPBondFeaturizer\n",
    "\n",
    "node_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='feat')\n",
    "edge_featurizer = AttentiveFPBondFeaturizer(bond_data_field='feat')\n",
    "dataset = MoleculeCSVDataset(df, \n",
    "                             node_featurizer=node_featurizer,\n",
    "                             edge_featurizer=edge_featurizer,\n",
    "                             smiles_column='smiles',\n",
    "                             task_names=['expt'],\n",
    "                             cache_file_path='dglgraph.bin')\n",
    "print('dataset size:', len(dataset))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4625ab",
   "metadata": {},
   "source": [
    "## Section 4: トレーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c674dc",
   "metadata": {},
   "source": [
    "### Dataset分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17becebf",
   "metadata": {},
   "source": [
    "まず、データセットをトレーニング、バリデーション、テストのサブセットに分割する必要があります。これらは、分子をBemis-Murcko Scaffoldsに基づいてグループ化され分割されるものです。こうすることで、異なるサブセット内の分子がより構造的に異なることを促し、現実世界の分布外問題に類似すると考えられています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import ScaffoldSplitter\n",
    "\n",
    "train_set, val_set, test_set = ScaffoldSplitter.train_val_test_split(\n",
    "    dataset, frac_train=0.8, frac_val=0.1, \n",
    "    frac_test=0.1, scaffold_func='smiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80271f05",
   "metadata": {},
   "source": [
    "### Data Loaderの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6257a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_molgraphs(data):\n",
    "    smiles, graphs, labels, masks = map(list, zip(*data))\n",
    "\n",
    "    bg = dgl.batch(graphs)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    masks = torch.stack(masks, dim=0)\n",
    "\n",
    "    return smiles, bg, labels, masks\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, \n",
    "                          shuffle=True, collate_fn=collate_molgraphs)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=batch_size,\n",
    "                        collate_fn=collate_molgraphs)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size,\n",
    "                         collate_fn=collate_molgraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e287e5d",
   "metadata": {},
   "source": [
    "### モデル初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0fe641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from dgllife.model import AttentiveFPPredictor\n",
    "from torch.optim import Adam\n",
    "\n",
    "model = AttentiveFPPredictor(\n",
    "    node_feat_size=node_featurizer.feat_size(),\n",
    "    edge_feat_size=edge_featurizer.feat_size(),\n",
    "    n_tasks=dataset.n_tasks\n",
    ")\n",
    "loss_criterion = nn.SmoothL1Loss(reduction='none')\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08579ac5",
   "metadata": {},
   "source": [
    "### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ba721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "from dgllife.utils import Meter\n",
    "\n",
    "def run_a_train_epoch(model, data_loader, loss_criterion, optimizer):\n",
    "    model.train()\n",
    "    train_meter = Meter()\n",
    "    for _, batch_data in enumerate(data_loader):\n",
    "        smiles, bg, labels, masks = batch_data\n",
    "        if len(smiles) == 1:\n",
    "            # Avoid potential issues with batch normalization\n",
    "            continue\n",
    "        \n",
    "        pred = model(bg, bg.ndata['feat'], bg.edata['feat'])\n",
    "        loss = (loss_criterion(pred, labels) * (masks != 0).float()).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_meter.update(pred, labels, masks)\n",
    "    return np.mean(train_meter.compute_metric('r2'))\n",
    "\n",
    "def run_an_eval_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    eval_meter = Meter()\n",
    "    for _, batch_data in enumerate(data_loader):\n",
    "        smiles, bg, labels, masks = batch_data\n",
    "        pred = model(bg, bg.ndata['feat'], bg.edata['feat'])\n",
    "        eval_meter.update(pred, labels, masks)\n",
    "    return np.mean(eval_meter.compute_metric('r2'))\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_r2 = run_a_train_epoch(model, train_loader, loss_criterion, optimizer)\n",
    "    val_r2 = run_an_eval_epoch(model, val_loader)\n",
    "    print('epoch {:d} | train r2 {:.4f} | val r2 {:.4f}'.format(epoch, train_r2, val_r2))\n",
    "test_r2 = run_an_eval_epoch(model, test_loader)\n",
    "print('test r2 {:.4f}'.format(test_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5c478",
   "metadata": {},
   "source": [
    "一度学習したモデルを保存しておけば、必要に応じて他の分子に適用することができます。\n",
    "\n",
    "1-4項は、ここでのコマンドラインインターフェイスのサブセットです。 [here](https://github.com/awslabs/dgl-lifesci/tree/master/examples/property_prediction/csv_data_configuration)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491eff9",
   "metadata": {},
   "source": [
    "## Section 5: Attention Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e5de8",
   "metadata": {},
   "source": [
    "AttentiveFPはアテンションベースのGNNです。ここでは、ある分子に対する学習済みモデルのAttentionを取得し、プロットします。これにより、今回のモデルが、入力のどこを重視して予測したかを把握することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd62044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from IPython.display import SVG, display\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "\n",
    "smiles, g, _, _ = dataset[0]\n",
    "_, atom_weights = model(g, g.ndata['feat'], g.edata['feat'], get_node_weight=True)\n",
    "# atom_weights is a list of length 2\n",
    "# we use the second suite of atom weights for visualization in this demo\n",
    "atom_weights = atom_weights[-1]\n",
    "\n",
    "# min-max normalization to make it easier to distinguish attention values\n",
    "min_value = torch.min(atom_weights)\n",
    "max_value = torch.max(atom_weights)\n",
    "atom_weights = (atom_weights - min_value) / (max_value - min_value)\n",
    "\n",
    "# Conver the weights to atom colors\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=1.28)\n",
    "cmap = cm.get_cmap('Oranges')\n",
    "plt_colors = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "atom_colors = {i: plt_colors.to_rgba(atom_weights[i].data.item()) \n",
    "               for i in range(g.num_nodes())}\n",
    "\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "rdDepictor.Compute2DCoords(mol)\n",
    "drawer = rdMolDraw2D.MolDraw2DSVG(280,280)\n",
    "drawer.SetFontSize(1)\n",
    "op = drawer.drawOptions()\n",
    "    \n",
    "mol = rdMolDraw2D.PrepareMolForDrawing(mol)\n",
    "drawer.DrawMolecule(mol, highlightAtoms=range(g.num_nodes()),highlightBonds=[],\n",
    "                    highlightAtomColors=atom_colors)\n",
    "drawer.FinishDrawing()\n",
    "svg = drawer.GetDrawingText()\n",
    "svg = svg.replace('svg:','')\n",
    "display(SVG(svg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dff29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
