{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f356f520",
   "metadata": {},
   "source": [
    "# GNNを用いたCOVID-19 mRNAワクチン分解率予測\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d93be0",
   "metadata": {},
   "source": [
    "## 1. ライブラリとデータセットの準備\n",
    "\n",
    "今回は [OpenVaccine data hosted on Kaggle](https://www.kaggle.com/competitions/stanford-covid-vaccine/overview)をデータセットとして用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3a8dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install dgl dgllife biopython seaborn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59121c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Download RNA stability data\n",
    "mkdir -p OpenVaccine\n",
    "\n",
    "wget https://d2125kp0qwrvcx.cloudfront.net/OpenVaccine/train.json -P OpenVaccine\n",
    "wget https://d2125kp0qwrvcx.cloudfront.net/OpenVaccine/test.json -P OpenVaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b21910",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'OpenVaccine/train.json'\n",
    "test_file = 'OpenVaccine/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Iterator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39125618",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utils for parsing the RNA data\n",
    "'''\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "\n",
    "token_to_idx = {\n",
    "    'sequence': {x:i for i, x in enumerate('ACGU')}, # residue_to_idx\n",
    "    'structure': {x:i for i, x in enumerate('().')},\n",
    "    'predicted_loop_type': {x:i for i, x in enumerate('BEHIMSX')},\n",
    "}\n",
    "\n",
    "def get_couples(structure):\n",
    "    \"\"\"\n",
    "    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n",
    "    The assigned list is used to keep track of the assigned opening parenthesis\n",
    "    \"\"\"\n",
    "    opened = [idx for idx, i in enumerate(structure) if i == '(']\n",
    "    closed = [idx for idx, i in enumerate(structure) if i == ')']\n",
    "\n",
    "    assert len(opened) == len(closed)\n",
    "    assigned = []\n",
    "    couples = []\n",
    "\n",
    "    for close_idx in closed:\n",
    "        for open_idx in opened:\n",
    "            if open_idx < close_idx:\n",
    "                if open_idx not in assigned:\n",
    "                    candidate = open_idx\n",
    "            else:\n",
    "                break\n",
    "        assigned.append(candidate)\n",
    "        couples.append([candidate, close_idx])\n",
    "        \n",
    "    assert len(couples) == len(opened)\n",
    "    return couples\n",
    "\n",
    "\n",
    "def build_edge_list(couples: list, size: int) -> tuple:\n",
    "    '''\n",
    "    Build edge list representation of the grap from `couples`, the output \n",
    "    of `get_couples`. The output of this function will be used to for \n",
    "    constructing dgl graph. \n",
    "    '''\n",
    "    src, dst = [], []\n",
    "    for i in range(size):\n",
    "        if i < size - 1:\n",
    "            # neigbouring bases are linked as well\n",
    "            src.append(i), \n",
    "            dst.append(i + 1)\n",
    "        if i > 0:\n",
    "            src.append(i)\n",
    "            dst.append(i - 1)\n",
    "    \n",
    "    for i, j in couples:\n",
    "        src.extend([i, j])\n",
    "        dst.extend([j, i])\n",
    "    \n",
    "    return src, dst\n",
    "\n",
    "def row_to_graph(row: pd.Series) -> dgl.DGLGraph:\n",
    "    '''\n",
    "    Process a row in the RNA data frame and convert to\n",
    "    a dgl.DGLGraph object.\n",
    "    '''\n",
    "    couples = get_couples(row['structure'])\n",
    "    edge_list = build_edge_list(couples, len(row['structure']))\n",
    "    # build a dgl.graph\n",
    "    g = dgl.graph(edge_list)\n",
    "    # one-hot encoding for three types of node features\n",
    "    node_features = []\n",
    "    for node_feature_col in token_to_idx:\n",
    "        # for each node, perform categorical encoding \n",
    "        node_feature = torch.tensor([token_to_idx[node_feature_col][x] for x in row[node_feature_col]])\n",
    "        # then convert to one-hot\n",
    "        node_feature = F.one_hot(node_feature, num_classes=len(token_to_idx[node_feature_col]))\n",
    "        node_features.append(node_feature)\n",
    "    node_features = torch.cat(node_features, axis=1)\n",
    "    # attach as node features \n",
    "    g.ndata['h'] = node_features.to(torch.float32)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3eb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNADataset(data.Dataset):\n",
    "    '''mRNA stability prediction dataset'''\n",
    "    def __init__(self, df, pred_cols=['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C'], is_train=True):\n",
    "        self.df = df\n",
    "        self.pred_cols = pred_cols\n",
    "        self.n_outputs = len(pred_cols)\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        g = row_to_graph(row)\n",
    "        \n",
    "        if self.is_train:\n",
    "            target = np.array(row[self.pred_cols].values.tolist()).T\n",
    "            target = torch.tensor(target, dtype=torch.float32) # shape: (n_labeled_nodes, len(pred_cols))\n",
    "\n",
    "            n_labeled_nodes = target.shape[0]\n",
    "            n_nodes = g.num_nodes()\n",
    "\n",
    "            node_labels = torch.zeros([n_nodes, len(self.pred_cols)], dtype=torch.float32)        \n",
    "            node_labels[:n_labeled_nodes] = target\n",
    "            g.ndata['target'] = node_labels # shape: (n_nodes, len(pred_cols))\n",
    "\n",
    "            train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "            train_mask[:n_labeled_nodes] = True        \n",
    "            g.ndata['train_mask'] = train_mask # shape: (n_nodes, )        \n",
    "        return g\n",
    "\n",
    "    @property\n",
    "    def feature_dim(self):\n",
    "        g = self.__getitem__(0)\n",
    "        return g.ndata['h'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87967b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the data into data frames\n",
    "train = pd.read_json(train_file, lines=True)\n",
    "test = pd.read_json(test_file, lines=True)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f316d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298410e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71733b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RNADataset(train)\n",
    "test_dataset = RNADataset(test, is_train=False)\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9379f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one RNA graph in the dataset:\n",
    "i = 0\n",
    "g = train_dataset[i]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb660a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of node features:', g.ndata['h'].shape)\n",
    "g.ndata['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of node targets:', g.ndata['target'].shape)\n",
    "print('labels:', train_dataset.pred_cols)\n",
    "g.ndata['target'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6d464",
   "metadata": {},
   "source": [
    "### 1.2. RNA分子を可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d76a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98003eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the raw features from the data frame:\n",
    "seq = train.loc[i, 'sequence']\n",
    "print(seq)\n",
    "predicted_loop_type = train.loc[i, 'predicted_loop_type']\n",
    "print(predicted_loop_type)\n",
    "structure = train.loc[i, 'structure']\n",
    "\n",
    "# convert to an undirected networkx graph\n",
    "mol_graph = dgl.to_networkx(g).to_undirected()\n",
    "print(mol_graph.number_of_nodes(), mol_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(mol_graph)\n",
    "nx.draw(mol_graph, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_residues = mol_graph.number_of_nodes()\n",
    "\n",
    "# label nodes by the index and residue type\n",
    "numbered_seq = ['%d%s'%(idx, letter) for idx, letter in zip(range(n_residues), seq)]\n",
    "node_labels = dict(zip(range(n_residues), numbered_seq))\n",
    "\n",
    "# color by predicted_loop_type\n",
    "color_palette = sns.color_palette()\n",
    "node_colors = [color_palette[token_to_idx['predicted_loop_type'][loop_type]] for loop_type in predicted_loop_type]\n",
    "\n",
    "nx.draw(mol_graph, pos, \n",
    "        labels=node_labels,\n",
    "        node_color=node_colors\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeda412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color by reactivity\n",
    "reactivities = train.loc[i, 'reactivity'].copy()\n",
    "# fill 0's for trailing residues\n",
    "reactivities.extend([0] * (n_residues - len(reactivities)))\n",
    "\n",
    "nx.draw(mol_graph, pos, \n",
    "        labels=node_labels,\n",
    "        node_color=reactivities,\n",
    "        cmap='Reds'\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03c045",
   "metadata": {},
   "source": [
    "## 2. GNNモデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.model import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebed532",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'num_layers': 2,\n",
    "    'hidden_feats': 8,\n",
    "    'dropout': 0.2,\n",
    "    'residual': False,\n",
    "    'batchnorm': False,\n",
    "}\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(\n",
    "    in_feats=train_dataset.feature_dim,\n",
    "    hidden_feats=[model_config['hidden_feats'] for _ in range(model_config['num_layers'] - 1)] + [train_dataset.n_outputs],\n",
    "    activation=[F.relu for _ in range(model_config['num_layers'] - 1)] + [None],\n",
    "    residual=[model_config['residual'] for _ in range(model_config['num_layers'])],\n",
    "    batchnorm=[model_config['batchnorm'] for _ in range(model_config['num_layers'])],\n",
    "    dropout=[model_config['dropout'] for _ in range(model_config['num_layers'] - 1)] + [0]\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb54ce",
   "metadata": {},
   "source": [
    "## 3. Train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    'frac_train': 0.8,\n",
    "    'lr': 1e-3,\n",
    "    'n_epochs': 10,\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 0,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "N = train.shape[0]\n",
    "train_idx = np.random.choice(N, int(train_config['frac_train'] * N), replace=False)\n",
    "valid_idx = np.setdiff1d(np.arange(N), train_idx)\n",
    "print(train_idx.shape, valid_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RNADataset(train.iloc[train_idx])\n",
    "train_loader = data.DataLoader(train_dataset, \n",
    "                               batch_size=train_config['batch_size'], \n",
    "                               shuffle=True, \n",
    "                               pin_memory=True,\n",
    "                               num_workers=train_config['num_workers'], \n",
    "                               collate_fn=dgl.batch\n",
    "                              )\n",
    "\n",
    "valid_dataset = RNADataset(train.iloc[valid_idx])\n",
    "valid_loader = data.DataLoader(valid_dataset, \n",
    "                               batch_size=train_config['batch_size'], \n",
    "                               shuffle=False, \n",
    "                               pin_memory=True,\n",
    "                               num_workers=train_config['num_workers'], \n",
    "                               collate_fn=dgl.batch\n",
    "                              )\n",
    "\n",
    "print(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4906975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, criterion, optimizer, device):\n",
    "    '''Train model for one epoch'''\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    train_loss = []\n",
    "    \n",
    "    for index, graphs in enumerate(train_loader):\n",
    "        graphs = graphs.to(device)\n",
    "        preds = model(graphs, graphs.ndata['h'])\n",
    "        train_mask = graphs.ndata['train_mask']\n",
    "        targets = graphs.ndata['target']\n",
    "        \n",
    "        loss = criterion(preds[train_mask], targets[train_mask])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    train_loss_avg = np.mean(train_loss)\n",
    "    print(f\"Train loss {train_loss_avg}\")\n",
    "    return train_loss_avg\n",
    "    \n",
    "def eval_fn(model, valid_loader, criterion, device):\n",
    "    '''Evaluate model'''\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    \n",
    "    for index, graphs in enumerate(valid_loader):\n",
    "        graphs = graphs.to(device)\n",
    "        preds = model(graphs, graphs.ndata['h'])\n",
    "        train_mask = graphs.ndata['train_mask']\n",
    "        targets = graphs.ndata['target']\n",
    "        \n",
    "        loss = criterion(preds[train_mask], targets[train_mask])\n",
    "        eval_loss.append(loss.item())\n",
    "    \n",
    "    eval_loss_avg = np.mean(eval_loss)\n",
    "    print(f\"Valid loss {eval_loss_avg}\")\n",
    "    return eval_loss_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=train_config['lr'], weight_decay=0.0)\n",
    "\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "for epoch in range(train_config['n_epochs']):\n",
    "    print('#################')\n",
    "    print('###Epoch:', epoch)\n",
    "\n",
    "    train_loss = train_fn(model, train_loader, criterion, optimizer, device)\n",
    "    eval_loss = eval_fn(model, valid_loader, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    eval_losses.append(eval_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675146b",
   "metadata": {},
   "source": [
    "## 4. テストデータの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2290477",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = test_dataset[0]\n",
    "test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted_node_labels = model(test_graph.to(device), \n",
    "                              test_graph.ndata['h'].to(device))\n",
    "predicted_node_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d398b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723f047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d5d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
